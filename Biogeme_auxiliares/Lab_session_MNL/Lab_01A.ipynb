{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demanda de transporte\n",
    "\n",
    "## `Auxiliar: Redes neuronales artificiales`\n",
    "\n",
    "**Junio 2024**<br>\n",
    "**Gabriel Nova & Sander van Cranenburgh** <br>\n",
    "**G.N.Nova@tudelft.nl** <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Application: Modelling neighbourhood choices`\n",
    "\n",
    "In this lab session, we will analyse neighbourhood location choice behaviour. Understanding people's preferences over neighbourhood characteristics is crucial for city planners when they (re)develop neighbourhoods or devise policies to tackle e.g. residential segregation. During this lab session, you will apply discrete choice models to uncover people's preferences over attributes, such as the distance to the city centre and the share of foreigners in their neighbourhood. Also, you will explore whether preferences interact with covariates such as age, gender, home ownership, car ownership and urbanisation level. While doing so, you will test various utility specifications and interpret the modelling outcomes of discrete choice models.\n",
    "\n",
    "For this study, we use data from a Stated Choice (SC) experiment, which was conducted between 2017 and 2018 in four European cities: Hanover, Mainz, Bern, and Zurich.\n",
    "\n",
    "![SC](./data/sc_experiment.png)\n",
    "\n",
    "**`Learning objectives lab session 01A`**\n",
    "\n",
    "After completing the following lab session, you will be able to:\n",
    "* Discover choice data\n",
    "* Estimate RUM-based multinomial logit discrete choice models using the Python package called `Biogeme`\n",
    "* Interpret the modelling results of RUM-MNL models\n",
    "* Forecast market shares by applying an estimated discrete choice model\n",
    "\n",
    "\n",
    "**`This lab consists of 3 parts and has 4 exercises`**\n",
    "\n",
    "**Part 1**: Load and explore the data set\n",
    "- Exercise 1: \"Representativeness of the sample\"\n",
    "\n",
    "**Part 2**: The linear-additive RUM-MNL model\n",
    "- Exercise 2: \"Interpreting modelling outcomes\"\n",
    "- Excerise 3: \"Attribute importance\"\n",
    "\n",
    "**Part 3**: Market share forecasting for Zurich\n",
    "- Excerise 4: \"Forecasting\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Import packages`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will import all the Python libraries that we will use in this lab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, log, exp\n",
    "\n",
    "# General python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from pathlib import Path\n",
    "\n",
    "# Pandas setting to show all columns when displaying a pandas dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1. Load and explore the data set` <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Load the data set`** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create that path to the data file\n",
    "data_path =  Path(f'data/choice_data_cleaned.dat')\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the choice data, using `read_csv()` from Pandas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data as a pandas dataframe\n",
    "df = pd.read_csv(data_path, sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Explore the data set`**<br>\n",
    "\n",
    "Now, let's explore the data set and examine the variables in the data.<br>\n",
    "You can use `head()` to look at the first 5 rows of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of variables**<br>\n",
    "\n",
    "The number concatenated to the variable refers to the alternative. Hence, `STORES1` is the column containing the attribute levels of alternative 1 for attribute STORES.<br>\n",
    "\n",
    "| Variable       | Description                                                    | Type/Levels |\n",
    "|-------------|----------------------------------------------------------------|--------------|\n",
    "| `ID`        | This is the ID number of the respondent                         | Integer      |\n",
    "| `TASK_ID`   | This is the number of the respondent's task of choice           | Integer      |\n",
    "| `STORES`    | Distance to grocery store in walking minutes                    | 2 Min., 5 Min., 10 Min., 15 Min.     |\n",
    "| `TRANSPORT` | Distance to public transportation in walking minutes            | 2 Min., 5 Min., 10 Min., 15 Min.      |\n",
    "| `CITY`      | Distance to city centre in km                                   | Below 1 km, 1 to 2 km, 3 to 4 km, over 4 km      |\n",
    "| `NOISE`     | Street traffic noise                                            | 1 = None, 2 = Little, 3 = Meduim, 4 = High      |\n",
    "| `GREEN`     | Green areas in residential area                                 | 1 = None, 2 = Few, 3 = Some, 4 = Many       |\n",
    "| `FOREIGN`   | Share of foreigners in residential areas                        | 0.10, 0.20, 0.30, 0.40      |\n",
    "| `CHOICE`    | Indicates the choice.                                           | Integer  |\n",
    "| `RESPCITY`  | Indicates the city. 1 = Mainz, 2 = Hanover, 3 = Bern, 4 = Zurich| Categorical  |\n",
    "| `WOMAN`     | Indicates 1 if woman and 0 otherwise                            | Binary       |\n",
    "| `AGE`       | Age in years                                                    | Integer      |\n",
    "| `ENVCONC`   | Environmental concern from 1 to 5, with 5 being the highest degree of concern | Ordinal |\n",
    "| `EDUYEARS`  | Number of years in education                                    | Numeric      |\n",
    "| `RESPFOREIGN`| 1 if the respondent is a foreigner, 0 otherwise                | Binary       |\n",
    "| `HOMEOWNER` | Indicates 1 if the respondent is a home owner and 0 otherwise   | Binary       |\n",
    "| `CAROWNER`  | Indicates 1 if the respondent is a car owner and 0 otherwise    | Binary       |\n",
    "| `JOB`       | 1 if the respondent is working, 0 otherwise                     | Binary       |\n",
    "| `NONWESTERN`| 1 if the respondent is non-western, 0 otherwise                 | Binary       |\n",
    "| `WESTERN`   | 1 if the respondent is western, 0 otherwise                     | Binary       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Descriptive statistics`**<br>\n",
    "\n",
    "We can use `describe()` to view descriptive statistics, such as count, mean, std, min, percentiles, and max about the **attribute levels** of the alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes =   ['STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1', 'FOREIGN1', \n",
    "                'STORES2', 'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2', 'FOREIGN2',\n",
    "                'STORES3', 'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3', 'FOREIGN3']\n",
    "round(df[attributes].describe(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Frequency and percentage of choices`**<br>\n",
    "\n",
    "When modelling choices, we are also interested in the frequency at which alternatives are chosen. In experiments with **unlabelled** alternatives (like this one), this analysis tells us whether the choices are 'balanced'. This means that the alternatives have been chosen in a similar proportion. If the data are not balanced, it may indicate that the experimental design was not sufficiently randomised. (In the lectures by Eric Molin you will learn more about the design of choice experiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the number of times each  alternative is chosen\n",
    "choice_freq = df['CHOICE'].value_counts()\n",
    "\n",
    "# Calculate the percentage of the chosen alternatives\n",
    "choice_percent = round(choice_freq / len(df['CHOICE']) * 100,2)\n",
    "\n",
    "# Table Summary\n",
    "choice_table = pd.DataFrame({'Choice': choice_freq.index, 'Frequency': choice_freq.values, 'Percentage':choice_percent.values} )\n",
    "\n",
    "# Show the table\n",
    "choice_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, all alternatives attain an (almost) equal share. This shows the design of the experiment was sufficiently randomised, and we do not need to account for artefacts arising from the experimental design (e.g. using constants)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Exercise 1: Representativeness of the sample`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When modelling choice behaviour, it is also important to have a good understanding of whether the sample (i.e. the collected data) is representative of the target population. If you are working with a non-representative sample, the results and conclusions can not be generalised to the population. This is particularly important when the objective is to determine e.g. Willingness-to-pay estimates.<br>\n",
    "\n",
    "To assess whether the sample is representative of our target population, we compare the sample statistics of the socio-demographic variables with statistics of the population. Usually, population statistics are made available by the National Bureaus of Statistics. In the Netherlands, this institute is called CBS (Centraal Bureau voor de Statistiek)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the sample statistics.<br>\n",
    "\n",
    "`A` Identify the column with socio-demographic variables <br>\n",
    "`B` Use the describe() to describe the socio-demographic variables, and create histograms for the variables<br>\n",
    "`C` Reflect on the representativeness of the sample, without comparing them to the population statistics<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `2. The linear-additive RUM-MNL model` <br>\n",
    "\n",
    "Now that we have developed a feeling for our data, we can start with estimating discrete choice models. For this, we will use the Python package called `Biogeme`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Biogeme database`**<br>\n",
    "To use this package, we first need to create the data set as a Biogeme database object using `db.Database()`. This object contains the data in a format compatible with the library functions for model estimation in Biogeme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.Database takes as arguments (1) a name (string) and (2) a data set (pandas dataframe)\n",
    "biodata = db.Database('Neighboorhood_choice_data', df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Biogeme variables`**<br>\n",
    "\n",
    "Also, we need to create Biogeme objects for all the variables in our data set that we want to use in our model specifications.<br>\n",
    "The `Variable()` function creates an object that represents the variable values and will allow it to be included in the model estimation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create Variable objects for each of the variables in the data set that we want to use in the model\n",
    "\n",
    "# Attributes of alternative 1\n",
    "STORES1     = Variable('STORES1')\n",
    "TRANSPORT1  = Variable('TRANSPORT1')\n",
    "CITY1       = Variable('CITY1')\n",
    "NOISE1      = Variable('NOISE1')\n",
    "GREEN1      = Variable('GREEN1')\n",
    "FOREIGN1    = Variable('FOREIGN1')\n",
    "\n",
    "# Attributes of alternative 2    \n",
    "STORES2     = Variable('STORES2')\n",
    "TRANSPORT2  = Variable('TRANSPORT2')\n",
    "CITY2       = Variable('CITY2')\n",
    "NOISE2      = Variable('NOISE2')\n",
    "GREEN2      = Variable('GREEN2')\n",
    "FOREIGN2    = Variable('FOREIGN2')\n",
    "    \n",
    "# Attributes of alternative 3\n",
    "STORES3     = Variable('STORES3')\n",
    "TRANSPORT3  = Variable('TRANSPORT3')\n",
    "CITY3       = Variable('CITY3')\n",
    "NOISE3      = Variable('NOISE3')\n",
    "GREEN3      = Variable('GREEN3')\n",
    "FOREIGN3    = Variable('FOREIGN3')\n",
    "\n",
    "# The choice\n",
    "CHOICE      = Variable('CHOICE')\n",
    "\n",
    "# Socio-economic variables\n",
    "AGE         = Variable('AGE')\n",
    "WOMAN       = Variable('WOMAN')\n",
    "HOMEOWNER   = Variable('HOMEOWNER')\n",
    "CAROWNER    = Variable('CAROWNER')\n",
    "RESPCITY    = Variable('RESPCITY')\n",
    "JOB         = Variable('JOB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`The linear-additive utility specification`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with defining the utility specification of the model that we wish to estimate.<br>\n",
    "\n",
    "For that, we must define the parameters to be estimated and specify the utility functions.<br>\n",
    "\n",
    "In the linear-additive RUM-MNL model, the observed utility is *V* for alternative *i* is given by:\n",
    "\n",
    "$V_i = \\beta_1 \\cdot \\text{x}_{1i} + \\beta_2 \\cdot \\text{x}_{2i} + \\ldots + \\beta_M \\cdot \\text{x}_{Mi}  $\n",
    "\n",
    "Where:\n",
    "- $\\beta_1, \\beta_2, \\ldots, \\beta_M$ denote the marginal utility associated with each attribute $m$.\n",
    "- $\\text{x}_{1i}, \\text{x}_{2i}, \\ldots, \\text{x}_{Mi} $ correspond to the attribute values alternative *i*.\n",
    "\n",
    "The cell below creates this utility function in Biogeme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a name to the model    \n",
    "model_name = 'Linear-additive RUM-MNL'\n",
    "\n",
    "# Define the model parameters, using the function \"Beta()\", in which you must define:\n",
    "# the name of the parameter,\n",
    "# starting value, \n",
    "# lower bound,\n",
    "# upper bound, \n",
    "# 0 or 1, indicating if the parameter must be estimated. 0 means estimated, 1 means fixed to the starting value. \n",
    "B_stores    = Beta('B_stores'   , 0, None, None, 0)\n",
    "B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "B_city      = Beta('B_city'     , 0, None, None, 0)\n",
    "B_noise     = Beta('B_noise'    , 0, None, None, 0)\n",
    "B_green     = Beta('B_green'    , 0, None, None, 0)\n",
    "B_foreign   = Beta('B_foreign'  , 0, None, None, 0)\n",
    "\n",
    "# Define the utility functions\n",
    "V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Estimation function`** \n",
    "\n",
    "Now that we have specified the model, we need to estimate it. To do so, we create the following function `estimate_mnl` which we can re-use.\n",
    "\n",
    "The estimation function takes the following inputs:\n",
    "* Systematic utilities function (**V1, V2, V3**)\n",
    "* Chosen alternatives array (**CHOICE**)\n",
    "* Database which contains the relevant attributes and characteristics (**database**)\n",
    "* Model name (**\"string\"**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function estimates the MNL model and returns the estimation results\n",
    "# input values: utilities for all three alternatives, the choices, the database, and the model name\n",
    "\n",
    "def estimate_mnl(V1,V2,V3,CHOICE,database,name):\n",
    "    \n",
    "    # Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "    V = {1: V1, 2: V2, 3: V3}\n",
    "        \n",
    "    # Create a dictionary called av to describe the availability conditions of each alternative, where 1 indicates that the alternative is available, and 0 indicates that the alternative is not available.\n",
    "    # This shows that all alternatives were available to all respondents. \n",
    "    av = {1: 1, 2: 1, 3: 1} \n",
    "\n",
    "    # Define the choice model: The function models.logit() computes the MNL choice probabilities of the chosen alternative given the V. \n",
    "    prob = models.logit(V, av, CHOICE)\n",
    "\n",
    "    # Define the log-likelihood   \n",
    "    LL = log(prob)\n",
    "   \n",
    "    # Create the Biogeme object containing the object database and the formula for the contribution to the log-likelihood of each row using the following syntax:\n",
    "    biogeme = bio.BIOGEME(database, LL)\n",
    "    \n",
    "    # The following syntax passes the name of the model:\n",
    "    biogeme.modelName = name\n",
    "\n",
    "    # Some object settings regaridng whether to save the results and outputs \n",
    "    biogeme.generate_pickle = False\n",
    "    biogeme.generate_html = False\n",
    "    biogeme.save_iterations = False\n",
    "    \n",
    "\n",
    "    # Syntax to calculate the null log-likelihood. The null-log-likelihood is used to compute the rho-square \n",
    "    biogeme.calculate_null_loglikelihood(av)\n",
    "\n",
    "    # This line starts the estimation and returns the results object.\n",
    "    results = biogeme.estimate()\n",
    "     \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Estimation`**\n",
    "\n",
    "We have created a biogeme database (biodata); we have defined our utility functions; and, we have created an estimation function to estimate MNL models (estimate_mnl).<br> \n",
    "Now, we only need to invoke the estimation by bringing these ingredients together. We pass the model specifications and the database to the estimation function. The function `estimate_mnl` returns an object which contains the estimation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the model\n",
    "results_MNL = estimate_mnl(V1,V2,V3,CHOICE,biodata,model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`View estimation results`**<br>\n",
    "\n",
    "**Estimation statistics**\n",
    "\n",
    "We can display a summary of the estimation statistics using `results.short_summary()` in which we see: \n",
    "\n",
    "* `Number of parameters`: Parameters being estimated.\n",
    "* `Sample size`: The number of observations in the data set (used for estimating the model).\n",
    "* `Excluded data`: The number of observations in the data set that were excluded for estimation.\n",
    "* `Null log-likelihood`: The log-likelihood of the null model.\n",
    "* `Final log-likelihood`: The log-likelihood of the estimated model.\n",
    "* `Likelihood ratio test (null)`: A statistical test comparing the null model's likelihood with the likelihood of the estimated model. \n",
    "* `Rho square (null)`: Quantifies how well the model explains the data compared to the null model.\n",
    "* `Rho bar square (null)`: Quantifies how well the model explains the data compared to the null model while penalising for the number of model parameters.\n",
    "* `Akaike Information Criterion (AIC)`: A measure that shows the goodness of fit of the model, where lower AIC values indicate better models.\n",
    "* `Bayesian Information Criterion (BIC)`: Similar to AIC, it penalizes model complexity more heavily, with lower values indicating better-fitting models while considering complexity.\n",
    "\n",
    "**Parameter estimates**\n",
    "\n",
    "We can display the estimated parameters using `results.getEstimatedParameters()`. Besides maximum likelihood estimates, we also see the associated standard errors, t-test values and p-values. The t-test values and p-values show the significance of the effect, demonstrating the generalisability of the relationship to the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the estimation statistics\n",
    "print(results_MNL.short_summary())\n",
    "\n",
    "# Get the model parameters in a pandas table and  print it\n",
    "beta_hat_MNL = results_MNL.get_estimated_parameters()\n",
    "statistics_MNL = results_MNL.get_general_statistics()\n",
    "print(beta_hat_MNL)\n",
    "\n",
    "# Store the LL of the MNL model for later use\n",
    "LL_MNL = results_MNL.data.logLike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Exercise 2:  Interpreting modelling outcomes`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the outcomes of your MNL model by answering the following questions:\n",
    "\n",
    "`A` Did the model converge?<br>\n",
    "\n",
    "`B` Are all estimated parameters of the expected sign?<br>\n",
    "\n",
    "`C` Are they significant at the 5% level? <br>\n",
    "\n",
    "`D` Based on the Likelihood Ratio Test: is the estimated model statistically superior to a  model that determines choices by ‘throwing a dice’? (i.e., the Null model). The [Chi-Square Distribution Table](https://github.com/SEN1221TUD/Q2_2024/blob/main/Lab_sessions/Lab_session_01/data/Chi-Square%20Distribution%20Table.pdf) can be found here.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Attribute importance`**<br>\n",
    "\n",
    "Next, we explore the importance of each attribute to the choice behaviour. To do so, we assess how much the model fit deteriorates when we fix one of the beta to zero. We do this for all six betas. A large drop in model fit indicates a great importance of attribute. After all, it means that without having access to that attribute, the model is less capable of explaining the choice behaviour.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the parameter names\n",
    "param_list = ['B_stores','B_transport','B_city','B_noise','B_green','B_foreign']\n",
    "\n",
    "# Create an empty dataframe with the parameter names as index (rows) to store the results\n",
    "df_out = pd.DataFrame(index = param_list + ['LL'])\n",
    "\n",
    "# Loop over the parameters\n",
    "for param_fix in param_list:\n",
    "    \n",
    "    model_name = f'linear-additive RUM-MNL with {param_fix} fixed to zero'\n",
    "   \n",
    "    # Parameters to be estimated\n",
    "    # Note that int(param_fix == 'B_stores') returns 1 if param_fix is 'B_stores', and 0 otherwise\n",
    "    B_stores    = Beta('B_stores'   , 0, None, None, int(param_fix == 'B_stores'))\n",
    "    B_transport = Beta('B_transport', 0, None, None, int(param_fix == 'B_transport'))\n",
    "    B_city      = Beta('B_city'     , 0, None, None, int(param_fix == 'B_city'))\n",
    "    B_noise     = Beta('B_noise'    , 0, None, None, int(param_fix == 'B_noise'))\n",
    "    B_green     = Beta('B_green'    , 0, None, None, int(param_fix == 'B_green'))\n",
    "    B_foreign   = Beta('B_foreign'  , 0, None, None, int(param_fix == 'B_foreign'))\n",
    "    \n",
    "    # Definition of the utility functions\n",
    "    V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "    V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "    V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3\n",
    "\n",
    "    # Estimate the model\n",
    "    results = estimate_mnl(V1,V2,V3,CHOICE,biodata,model_name)\n",
    "\n",
    "    # Store the parameter estimates in a dataframe\n",
    "    col = param_fix + '_fixed'\n",
    "    df_out.loc[:,col] = results.get_beta_values()\n",
    "\n",
    "    # Store the log-likelihood\n",
    "    df_out.loc['LL',col] = results.get_general_statistics()['Final log likelihood'][0]\n",
    "\n",
    "# Show the dataframe with the results\n",
    "df_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Exercise 3: Attribute importance`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` List the attributes from most important to least important, based on their impact on the model fit.\n",
    "\n",
    "`B` Use the Likelihood Ratio Statistic (LRS) to test, for each of the six models, whether the restricted model is statistically preferred over the unrestricted model (i.e. the linear-additive RUM-MNL model with LL = -8403.772 and 6 parameters).<br>\n",
    "<br>\n",
    "The LRS is given by: <br>\n",
    "<br>\n",
    "$LRS = -2 \\left[LL(\\beta_R)-LL(\\beta_U)\\right] $<br>\n",
    "<br>\n",
    "Where $\\beta_R$ and $\\beta_U$ correspond to the parameters estimated using a restricted and unrestricted model, respectively.<br>\n",
    "\n",
    "You need to compare the LRS with the critical $\\chi^2$ value associated with a specific significance level. If $LRS > \\chi^2_{df}$ , you can conclude that the unrestricted model better explains the data than the restricted model.<br>\n",
    "\n",
    "Use α = 0.01 as the critical threshold level of significance. The [Chi-Square Distribution Table](https://github.com/SEN1221TUD/Q2_2024/blob/main/Lab_sessions/Lab_session_01/data/Chi-Square%20Distribution%20Table.pdf) can be found here.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3. Market share forecasting for Zurich`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the municipality of Zurich plans to redevelop one of their least accessible neighbourhoods in the North: `Affoltern, Oerlikon, Seebach` (11). Figure 1 shows the neighbourhoods of Zurich. The municipality plans to develop a new shopping area and public transport hub in the neighbourhood. The idea is that this will make the neighbourhood more attractive to live in. But, these plans are costly. Therefore, to make an informed decision, the municipality needs to have a good understanding of the impact of increasing the accessibility in `Affoltern, Oerlikon, Seebach` on the residential demand in that neighbourhood. <br>\n",
    "\n",
    "The **current** situation - in terms of the attributes we have looked at in this study - is shown in the table below.<br>\n",
    "**After** the redevelopment, the average distance to grocery stores and public transport is 5 minutes (STORES = 5, TRANSPORT = 5) instead of 15 minutes.\n",
    "\n",
    "\n",
    "| neighbourhood name                        | ID         | CITY    | FOREIGN  | GREEN  | NOISE  | STORES   | TRANSPORT  |\n",
    "|-------------------------------------------|------------|---------|----------|--------|--------|----------|------------|\n",
    "| Altstadt                                  | 1          | 1       | 0.22     | 2      | 1      | 2        | 5          |\n",
    "| Enge, Wollishofen, Leimbach               | 2          | 4       | 0.16     | 4      | 3      | 5        | 10         |\n",
    "| Wiedikon                                  | 3          | 3       | 0.23     | 3      | 3      | 10       | 15         |\n",
    "| Aussersihl                                | 4          | 2       | 0.27     | 1      | 4      | 5        | 5          |\n",
    "| Industriequartier                         | 5          | 2       | 0.18     | 1      | 4      | 10       | 2          |\n",
    "| Oberstrass, Unterstrass                   | 6          | 3       | 0.16     | 3      | 3      | 10       | 10         |\n",
    "| Fluntern, Hottingen, Hirslanden, Witikon  | 7          | 4       | 0.16     | 4      | 1      | 10       | 15         |\n",
    "| Riesbach                                  | 8          | 3       | 0.18     | 3      | 3      | 5        | 15         |\n",
    "| Altstetten, Albisrieden                   | 9          | 4       | 0.31     | 3      | 2      | 5        | 10         |\n",
    "| Wipkingen, Höngg                          | 10         | 4       | 0.25     | 4      | 3      | 15       | 10         |\n",
    "| Affoltern, Oerlikon, Seebach              | 11         | 4       | 0.33     | 3      | 3      | 15       | 15         |\n",
    "| Schwamendingen                            | 12         | 4       | 0.36     | 4      | 3      | 5        | 10         |\n",
    "\n",
    "![Zurich](data/zurich.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inform this policy decision, we will use our estimated choice models. To do so, we take the following steps:\n",
    "1. We use our estimated MNL model to compute the choice probabilities of the neighbourhoods for the **current situation**\n",
    "2. We use our estimated MNL model to compute the choice probabilities of the neighbourhoods for the **future situation**\n",
    "3. We compare the probabilities between the present and future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data as a pandas dataframe\n",
    "data_path =  Path(f'data/zurich_data.csv')\n",
    "df_zurich = pd.read_csv(data_path, index_col=0)\n",
    "\n",
    "# Show the the dataframe\n",
    "df_zurich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually compute the utilities for each neighbourhood alternative in the present situation\n",
    "# Let's use our benchmark linear-additive MNL model\n",
    "V_zurich_present =  (beta_hat_MNL['Value']['B_city']      * df_zurich['CITY'] +\n",
    "                     beta_hat_MNL['Value']['B_foreign']   * df_zurich['FOREIGN'] + \n",
    "                     beta_hat_MNL['Value']['B_green']     * df_zurich['GREEN'] + \n",
    "                     beta_hat_MNL['Value']['B_noise']     * df_zurich['NOISE'] + \n",
    "                     beta_hat_MNL['Value']['B_stores']    * df_zurich['STORES'] + \n",
    "                     beta_hat_MNL['Value']['B_transport'] * df_zurich['TRANSPORT'])\n",
    "\n",
    "# Compute the market shares using the logit formula: Pi = exp(Vi)/sum(exp(Vj)) \n",
    "P_present = np.exp(V_zurich_present)/np.sum(np.exp(V_zurich_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually compute the market shares for each neighbourhood alternative in the future scenario\n",
    "\n",
    "# Create a copy of the dataframe, and change the accessibility of stores and transport in the neighbourhoods Affoltern, Oerlikon, and Seebach\n",
    "df_zurich_future = df_zurich.copy()\n",
    "df_zurich_future.loc['Affoltern, Oerlikon, Seebach','STORES'] = 5\n",
    "df_zurich_future.loc['Affoltern, Oerlikon, Seebach','TRANSPORT'] = 5\n",
    "\n",
    "# Manually compute the utilities for each neighbourhood alternative in the future situation\n",
    "V_zurich_future = (beta_hat_MNL['Value']['B_city']      * df_zurich_future['CITY'] +\n",
    "                   beta_hat_MNL['Value']['B_foreign']   * df_zurich_future['FOREIGN'] + \n",
    "                   beta_hat_MNL['Value']['B_green']     * df_zurich_future['GREEN'] + \n",
    "                   beta_hat_MNL['Value']['B_noise']     * df_zurich_future['NOISE'] + \n",
    "                   beta_hat_MNL['Value']['B_stores']    * df_zurich_future['STORES'] + \n",
    "                   beta_hat_MNL['Value']['B_transport'] * df_zurich_future['TRANSPORT'])\n",
    "\n",
    "# Compute the market shares using the logit formula\n",
    "P_future = np.exp(V_zurich_future)/np.sum(np.exp(V_zurich_future))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the market shares in the present and future scenarios\n",
    "df_zurich_marketshares = pd.DataFrame({'Present [%]': P_present*100, 'Future [%]': P_future*100})\n",
    "\n",
    "# Show the dataframe\n",
    "df_zurich_marketshares.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table shows that the market share of `Affoltern, Oerlikon, Seebach` increases substantially: it more than doubles.<br> Hence, the model suggests that increasing accessibility will make the neighbourhood considerably more attractive. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Exercise 4: Forecasting`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Determine which neighbourhoods lose the most market share in (a) absolute and (b) relative terms.<br>\n",
    "\n",
    "`B` Reflect on the behavioural realism of your results, especially w.r.t. the relative changes in market shares. <br>\n",
    "\n",
    "`C` Currently, `Affoltern, Oerlikon, Seebach` is a quiet urban area. The creation of a public transport hub there will likely increase the average noise levels. Our earlier analysis showed that noise is an important factor in the residential location choice. Therefore, a change in noise levels needs also to be taken into account. <br>\n",
    "\n",
    "* Create a plot showing how increasing noise for 1 to 4 leads to a deterioration of the market share of `Affoltern, Oerlikon, Seebach`. Thus, the *x*-axis shows the noise level, and the *y*-axis the market share.<br>\n",
    "\n",
    "* Based on your results, what would you recommend to the planners of Zurich?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Demanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
