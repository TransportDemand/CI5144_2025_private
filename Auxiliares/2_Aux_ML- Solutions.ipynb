{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demanda de transporte\n",
    "\n",
    "## `Auxiliar: Redes neuronales artificiales`\n",
    "\n",
    "**Junio 2024**<br>\n",
    "**Gabriel Nova** <br>\n",
    "**G.N.Nova@tudelft.nl** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Instrucciones`\n",
    "\n",
    "**Las sesiones de laboratorio son:**<br>\n",
    "* Entornos de aprendizaje donde trabajas con Jupyter y puedes resolver dudas.<br>\n",
    "* No son calificadas y no tienen que ser entregadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Configuración del entorno de trabajo`\n",
    "\n",
    "**Opción 1: Entorno local**<br>\n",
    "Descomenta la siguiente celda si estás ejecutando este cuaderno en tu entorno local, para instalar todas las dependencias en tu versión de Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opción 2: Google Colab**<br>\n",
    "Descomenta la siguiente celda si estás ejecutando este cuaderno en Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/TransportDemand/CI5144\n",
    "#!pip install -r CI5144/requirements_colab.txt\n",
    "#!mv \"/content/CI5144/Auxiliares/data\" /content/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Aplicación: Modelando elecciones de vecindarios` <br>\n",
    "En esta sesión de laboratorio, analizaremos el comportamiento de elección de vecindarios. Comprender las preferencias de las personas sobre las características de los vecindarios es crucial para los urbanistas cuando (re)desarrollan vecindarios o diseñan políticas para abordar, por ejemplo, la segregación residencial. Durante esta sesión de laboratorio, aplicará modelos de elección discreta para descubrir las preferencias de las personas sobre atributos como la distancia al centro de la ciudad y la proporción de extranjeros en su vecindario. Además, explorará si las preferencias interactúan con covariables como la edad, el género, la propiedad de la vivienda, la propiedad del automóvil y el nivel de urbanización. Mientras lo hace, probará varias especificaciones de utilidad e interpretará los resultados de los modelos de elección discreta.\n",
    "\n",
    "Para este estudio, utilizamos datos de un experimento de elección declarada, que se llevó a cabo entre 2017 y 2018 en cuatro ciudades europeas: Hanover, Mainz, Berna y Zurich.\n",
    "\n",
    "**`Objetivos de aprendizaje del auxiliar`**\n",
    "\n",
    "Después de completar el auxiliar, podrás:\n",
    "* Entrenar un Perceptrón Multicapa (MLP) en datos de elección.\n",
    "* Entrenar un modelo de elección híbrido, utilizando PyTorch.\n",
    "* Balance entre el el comportamiento esperado y el ajuste del modelo.\n",
    "* Reflexionar sobre las fortalezas y debilidades de los enfoques de modelado basados en datos y en teoría.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**`Este laboratorio consta de 4 partes`**\n",
    "\n",
    "**Parte 1**: Preparación de datos\n",
    "\n",
    "**Parte 2**: El modelo lineal-aditivo RUM-MNL\n",
    "- Ejercicio 1: \"Disposición a pagar por tiendas de comestibles\"\n",
    "\n",
    "**Parte 3**: El Perceptrón Multicapa\n",
    "- Ejercicio 2: \"Entrenamiento del modelo MLP\"\n",
    "- Ejercicio 3: \"Añadiendo las características socio-demográficas\"\n",
    "\n",
    "**Parte 4**: El modelo L-MNL\n",
    "- Ejercicio 4: \"Característica MLP\"\n",
    "- Ejercicio 5: \"Pronóstico utilizando el modelo L-MNL\"\n",
    "\n",
    "\n",
    "y comprende **`5`** ejercicios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Importar packages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Python packages and modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import getcwd\n",
    "from pathlib import Path\n",
    "\n",
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, log\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Preparar su base de datos**\n",
    "Para preparar la base de datos, haremos lo siguiente:<br>\n",
    "    1.1 Cargar la base de datos<br>\n",
    "    1.2 Limpiar y preparar la base de datos<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `i. Configurar el espacio de trabajo y cargar la base de datos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9720, 32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener el ruta a la base de datos\n",
    "data_path = Path(f'data/choice_data.dat')\n",
    "\n",
    "# Cargar datos de elección de modo en un pandas DataFrame\n",
    "df = pd.read_csv(data_path, sep='\\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción de variables**<br>\n",
    "\n",
    "Por lo tanto, se recomienda revisar la descripción de la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable       | Descripción                                                    | Tipo/Niveles |\n",
    "|----------------|---------------------------------------------------------------|--------------|\n",
    "| `ID`           | ID del encuestado                                             | Entero       |\n",
    "| `TASK_ID`      | Id de la tarea de elección                                    | Entero       |\n",
    "| `STORES`       | Minutos caminando a los supermercados        | 2 Min., 5 Min., 10 Min., 15 Min. |\n",
    "| `TRANSPORT`    | Minutos caminando al transporte público           | 2 Min., 5 Min., 10 Min., 15 Min. |\n",
    "| `CITY`         | Distancia al centro de la ciudad en km                        | Menos de 1 km, 1 a 2 km, 3 a 4 km, más de 4 km |\n",
    "| `NOISE`        | Ruido del tráfico en la calle                                 | 1 = Ninguno, 2 = Poco, 3 = Medio, 4 = Alto |\n",
    "| `GREEN`        | Áreas verdes en la zona residencial                           | 1 = Ninguno, 2 = Pocas, 3 = Algunas, 4 = Muchas |\n",
    "| `FOREIGN`      | Proporción de extranjeros en la zona residencial              | 0.10, 0.20, 0.30, 0.40 |\n",
    "| `CHOICE`       | Indica la elección                                            | Entero       |\n",
    "| `RESPCITY`     | Indica la ciudad. 1 = Mainz, 2 = Hanover, 3 = Berna, 4 = Zurich | Categórico   |\n",
    "| `WOMAN`        | Indica 1 si es mujer y 0 de lo contrario                      | Categórico      |\n",
    "| `AGE`          | Edad en años                                                  | Entero       |\n",
    "| `ENVCONC`      | Preocupación ambiental de 1 a 5, siendo 5 el grado más alto de preocupación | Ordinal     |\n",
    "| `EDUYEARS`     | Número de años de educación                                   | Numérico     |\n",
    "| `RESPFOREIGN`  | 1 si el encuestado es extranjero, 0 de lo contrario           | Categórico      |\n",
    "| `HOMEOWNER`    | Indica 1 si el encuestado es propietario de vivienda y 0 de lo contrario | Categórico      |\n",
    "| `CAROWNER`     | Indica 1 si el encuestado es propietario de un auto y 0 de lo contrario | Categórico      |\n",
    "| `JOB`          | 1 si el encuestado está trabajando, 0 de lo contrario         | Categórico      |\n",
    "| `NONWESTERN`   | 1 si el encuestado es no occidental, 0 de lo contrario        | Categórico      |\n",
    "| `WESTERN`      | 1 si el encuestado es occidental, 0 de lo contrario           | Categórico      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Inspeccionar, limpiar y preparar los datos**<br>\n",
    "Antes de empezar a analizar los datos, asegúrate de que sabes qué conoces las características que posee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TASK_ID</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ENVCONC</th>\n",
       "      <th>EDUYEARS</th>\n",
       "      <th>RESPFOREIGN</th>\n",
       "      <th>HOMEOWNER</th>\n",
       "      <th>CAROWNER</th>\n",
       "      <th>JOB</th>\n",
       "      <th>NONWESTERN</th>\n",
       "      <th>WESTERN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.00000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "      <td>9720.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4936.131276</td>\n",
       "      <td>19743.025103</td>\n",
       "      <td>7.972634</td>\n",
       "      <td>7.997737</td>\n",
       "      <td>3.006996</td>\n",
       "      <td>2.495576</td>\n",
       "      <td>2.502984</td>\n",
       "      <td>0.249095</td>\n",
       "      <td>8.007407</td>\n",
       "      <td>7.937449</td>\n",
       "      <td>...</td>\n",
       "      <td>206.288477</td>\n",
       "      <td>702.665432</td>\n",
       "      <td>1937.691427</td>\n",
       "      <td>3800.628807</td>\n",
       "      <td>823.193827</td>\n",
       "      <td>41.37572</td>\n",
       "      <td>617.895885</td>\n",
       "      <td>1564.486831</td>\n",
       "      <td>41.310700</td>\n",
       "      <td>41.247737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2791.776351</td>\n",
       "      <td>11167.105459</td>\n",
       "      <td>4.943312</td>\n",
       "      <td>4.969792</td>\n",
       "      <td>1.581009</td>\n",
       "      <td>1.121941</td>\n",
       "      <td>1.110794</td>\n",
       "      <td>0.111187</td>\n",
       "      <td>4.937217</td>\n",
       "      <td>4.933491</td>\n",
       "      <td>...</td>\n",
       "      <td>4531.586747</td>\n",
       "      <td>8084.394737</td>\n",
       "      <td>13772.314585</td>\n",
       "      <td>19083.662381</td>\n",
       "      <td>9035.133163</td>\n",
       "      <td>2028.26417</td>\n",
       "      <td>7832.731177</td>\n",
       "      <td>12407.404755</td>\n",
       "      <td>2028.265479</td>\n",
       "      <td>2028.266745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2541.000000</td>\n",
       "      <td>10162.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5003.500000</td>\n",
       "      <td>20012.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7305.000000</td>\n",
       "      <td>29218.250000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9825.000000</td>\n",
       "      <td>39300.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.00000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID       TASK_ID      STORES1   TRANSPORT1        CITY1  \\\n",
       "count  9720.000000   9720.000000  9720.000000  9720.000000  9720.000000   \n",
       "mean   4936.131276  19743.025103     7.972634     7.997737     3.006996   \n",
       "std    2791.776351  11167.105459     4.943312     4.969792     1.581009   \n",
       "min       2.000000      5.000000     2.000000     2.000000     1.000000   \n",
       "25%    2541.000000  10162.750000     2.000000     2.000000     2.000000   \n",
       "50%    5003.500000  20012.500000     5.000000     5.000000     4.000000   \n",
       "75%    7305.000000  29218.250000    10.000000    15.000000     5.000000   \n",
       "max    9825.000000  39300.000000    15.000000    15.000000     5.000000   \n",
       "\n",
       "            NOISE1       GREEN1     FOREIGN1      STORES2   TRANSPORT2  ...  \\\n",
       "count  9720.000000  9720.000000  9720.000000  9720.000000  9720.000000  ...   \n",
       "mean      2.495576     2.502984     0.249095     8.007407     7.937449  ...   \n",
       "std       1.121941     1.110794     0.111187     4.937217     4.933491  ...   \n",
       "min       1.000000     1.000000     0.100000     2.000000     2.000000  ...   \n",
       "25%       1.000000     2.000000     0.200000     5.000000     2.000000  ...   \n",
       "50%       3.000000     3.000000     0.200000    10.000000     5.000000  ...   \n",
       "75%       3.000000     3.000000     0.300000    10.000000    10.000000  ...   \n",
       "max       4.000000     4.000000     0.400000    15.000000    15.000000  ...   \n",
       "\n",
       "              WOMAN           AGE       ENVCONC      EDUYEARS   RESPFOREIGN  \\\n",
       "count   9720.000000   9720.000000   9720.000000   9720.000000   9720.000000   \n",
       "mean     206.288477    702.665432   1937.691427   3800.628807    823.193827   \n",
       "std     4531.586747   8084.394737  13772.314585  19083.662381   9035.133163   \n",
       "min        0.000000     18.000000      1.000000      8.000000      0.000000   \n",
       "25%        0.000000     34.000000      3.166667     13.000000      0.000000   \n",
       "50%        1.000000     44.000000      3.666667     16.500000      0.000000   \n",
       "75%        1.000000     56.000000      4.166667     18.000000      0.000000   \n",
       "max    99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
       "\n",
       "         HOMEOWNER      CAROWNER           JOB    NONWESTERN       WESTERN  \n",
       "count   9720.00000   9720.000000   9720.000000   9720.000000   9720.000000  \n",
       "mean      41.37572    617.895885   1564.486831     41.310700     41.247737  \n",
       "std     2028.26417   7832.731177  12407.404755   2028.265479   2028.266745  \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.00000      0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.00000      1.000000      1.000000      0.000000      0.000000  \n",
       "75%        0.00000      1.000000      1.000000      0.000000      0.000000  \n",
       "max    99999.00000  99999.000000  99999.000000  99999.000000  99999.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla de arriba proporciona información importante sobre las variables de la base de datos. El promedio y la desviación estándar (std) de algunas variables son altas. Por ejemplo, los valores medios de `WOMAN`, `AGE`, `EDUYEARS` son bastante más altos de lo esperado según la descripción de las variables. Esto podría indicar problemas en el conjunto de datos, la presencia de valores atípicos o valores perdidos. En la tabla anterior, puede verse que el número `99999` no coincide con los valores habituales de variables como `WOMEN`, `AGE` y `others`.<br>\n",
    "\n",
    "Esto sugiere que el valor `99999` se ha utilizado para representar `valores perdidos` en el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Conjunto de datos para la estimación`**<br>\n",
    "\n",
    "Dado nuestro objetivo de investigar el impacto de la edad, el sexo, la propiedad de la vivienda, la propiedad de un auto y la urbanización, tenemos que trabajar con las filas de los datos con valores que faltan en estas columnas. Afortunadamente, la proporción de datos que faltan en estas columnas es relativamente pequeña. Por lo tanto, una estrategia razonable en este caso es simplemente eliminar las filas de datos con valores que faltan en estas columnas. Otra estrategia podría haber sido imputar los valores de la media. Sin embargo, esta estrategia también tiene sus desventajas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TASK_ID</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>AGE</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>HOMEOWNER</th>\n",
       "      <th>CAROWNER</th>\n",
       "      <th>RESPCITY</th>\n",
       "      <th>JOB</th>\n",
       "      <th>EDUYEARS</th>\n",
       "      <th>ENVCONC</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4938.589460</td>\n",
       "      <td>19752.857839</td>\n",
       "      <td>7.981842</td>\n",
       "      <td>7.978299</td>\n",
       "      <td>3.007418</td>\n",
       "      <td>2.496678</td>\n",
       "      <td>2.503432</td>\n",
       "      <td>0.249302</td>\n",
       "      <td>8.002214</td>\n",
       "      <td>7.948406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250498</td>\n",
       "      <td>44.530115</td>\n",
       "      <td>0.532329</td>\n",
       "      <td>0.224092</td>\n",
       "      <td>0.624004</td>\n",
       "      <td>2.614703</td>\n",
       "      <td>0.735607</td>\n",
       "      <td>15.254650</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>1.958924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2798.272394</td>\n",
       "      <td>11193.089632</td>\n",
       "      <td>4.945691</td>\n",
       "      <td>4.966099</td>\n",
       "      <td>1.581524</td>\n",
       "      <td>1.121651</td>\n",
       "      <td>1.112332</td>\n",
       "      <td>0.111112</td>\n",
       "      <td>4.939272</td>\n",
       "      <td>4.931868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>13.463328</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.484406</td>\n",
       "      <td>1.108207</td>\n",
       "      <td>0.441034</td>\n",
       "      <td>2.702097</td>\n",
       "      <td>0.771467</td>\n",
       "      <td>0.813718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2535.000000</td>\n",
       "      <td>10138.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5032.500000</td>\n",
       "      <td>20128.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7335.000000</td>\n",
       "      <td>29338.250000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9813.000000</td>\n",
       "      <td>39252.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID       TASK_ID      STORES1   TRANSPORT1        CITY1  \\\n",
       "count  9032.000000   9032.000000  9032.000000  9032.000000  9032.000000   \n",
       "mean   4938.589460  19752.857839     7.981842     7.978299     3.007418   \n",
       "std    2798.272394  11193.089632     4.945691     4.966099     1.581524   \n",
       "min       2.000000      5.000000     2.000000     2.000000     1.000000   \n",
       "25%    2535.000000  10138.750000     5.000000     2.000000     2.000000   \n",
       "50%    5032.500000  20128.500000     5.000000     5.000000     4.000000   \n",
       "75%    7335.000000  29338.250000    10.000000    15.000000     5.000000   \n",
       "max    9813.000000  39252.000000    15.000000    15.000000     5.000000   \n",
       "\n",
       "            NOISE1       GREEN1     FOREIGN1      STORES2   TRANSPORT2  ...  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000  ...   \n",
       "mean      2.496678     2.503432     0.249302     8.002214     7.948406  ...   \n",
       "std       1.121651     1.112332     0.111112     4.939272     4.931868  ...   \n",
       "min       1.000000     1.000000     0.100000     2.000000     2.000000  ...   \n",
       "25%       1.000000     2.000000     0.200000     5.000000     2.000000  ...   \n",
       "50%       3.000000     3.000000     0.200000    10.000000     5.000000  ...   \n",
       "75%       4.000000     3.000000     0.300000    10.000000    10.000000  ...   \n",
       "max       4.000000     4.000000     0.400000    15.000000    15.000000  ...   \n",
       "\n",
       "          FOREIGN3          AGE        WOMAN    HOMEOWNER     CAROWNER  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000   \n",
       "mean      0.250498    44.530115     0.532329     0.224092     0.624004   \n",
       "std       0.112500    13.463328     0.498981     0.417006     0.484406   \n",
       "min       0.100000    18.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.100000    33.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.300000    44.000000     1.000000     0.000000     1.000000   \n",
       "75%       0.400000    56.000000     1.000000     0.000000     1.000000   \n",
       "max       0.400000    70.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          RESPCITY          JOB     EDUYEARS      ENVCONC       CHOICE  \n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000  \n",
       "mean      2.614703     0.735607    15.254650     3.625000     1.958924  \n",
       "std       1.108207     0.441034     2.702097     0.771467     0.813718  \n",
       "min       1.000000     0.000000     8.000000     1.000000     1.000000  \n",
       "25%       2.000000     0.000000    13.000000     3.166667     1.000000  \n",
       "50%       3.000000     1.000000    16.000000     3.666667     2.000000  \n",
       "75%       4.000000     1.000000    18.000000     4.166667     3.000000  \n",
       "max       4.000000     1.000000    18.000000     5.000000     3.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lista de características relevantes\n",
    "id         = ['ID', 'TASK_ID' ]\n",
    "attributes =   ['STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1', 'FOREIGN1', \n",
    "                'STORES2', 'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2', 'FOREIGN2',\n",
    "                'STORES3', 'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3', 'FOREIGN3']\n",
    "\n",
    "sociovars = ['AGE','WOMAN','HOMEOWNER','CAROWNER','RESPCITY', 'JOB', 'EDUYEARS', 'ENVCONC']\n",
    "\n",
    "# Crear una nueva instancia del dataframe, con los atributos, las variables socio-demográficas y la elección.\n",
    "dff = df[ id + attributes + sociovars + ['CHOICE']].copy()\n",
    "\n",
    "# Reemplazar 9999 por NaN\n",
    "dff = dff.replace(99999, np.nan)\n",
    "\n",
    "# Eliminar las filas con datos que faltan en las características relevantes\n",
    "dff = dff.dropna(subset=sociovars, how='any')\n",
    "\n",
    "dff.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recodificar las variables sociodemográficas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataframe con las variables socio demográficas relevantes\n",
    "df_sociovars  = dff[sociovars].astype(int)\n",
    "\n",
    "# Recodificar 'AGE' \n",
    "df_sociovars.loc[(      df_sociovars['AGE'] < 25), 'AGE'] = 1\n",
    "df_sociovars.loc[(25 <= df_sociovars['AGE']     ) &\n",
    "                 (      df_sociovars['AGE'] < 60), 'AGE'] = 2\n",
    "df_sociovars.loc[(60 <= df_sociovars['AGE']     ), 'AGE'] = 3\n",
    "\n",
    "# Recodificar 'EDUYEARS'\n",
    "df_sociovars.loc[(      df_sociovars['EDUYEARS'] < 10), 'EDUYEARS'] = 1\n",
    "df_sociovars.loc[(10 <= df_sociovars['EDUYEARS']     ) & \n",
    "                 (      df_sociovars['EDUYEARS'] < 14), 'EDUYEARS'] = 2\n",
    "df_sociovars.loc[(14 <= df_sociovars['EDUYEARS']     ), 'EDUYEARS'] = 3\n",
    "\n",
    "# Recodificar\n",
    "df_sociovars.loc[(     df_sociovars['ENVCONC'] < 3), 'ENVCONC'] = 1\n",
    "df_sociovars.loc[(3 <= df_sociovars['ENVCONC']    ) & \n",
    "                 (     df_sociovars['ENVCONC'] < 4), 'ENVCONC'] = 2\n",
    "df_sociovars.loc[(4 <= df_sociovars['ENVCONC']    ), 'ENVCONC'] = 3\n",
    "\n",
    "#Convertir variables categóricas en variables dummies utilizando pd.get_dummies()\n",
    "df_sociovars = pd.get_dummies(data = df_sociovars, prefix = sociovars, prefix_sep='_', columns = sociovars, drop_first = True, dtype=int)\n",
    "\n",
    "# Crear una variable con los nombres de las variables sociodemográficas\n",
    "features_socio = df_sociovars.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, cree el dataframe para el entrenamiento, que contiene el «ID», la «CHOICE», los atributos y las variables sociodemográficas codificados como dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9032, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>HOMEOWNER_1</th>\n",
       "      <th>CAROWNER_1</th>\n",
       "      <th>RESPCITY_2</th>\n",
       "      <th>RESPCITY_3</th>\n",
       "      <th>RESPCITY_4</th>\n",
       "      <th>JOB_1</th>\n",
       "      <th>EDUYEARS_2</th>\n",
       "      <th>EDUYEARS_3</th>\n",
       "      <th>ENVCONC_2</th>\n",
       "      <th>ENVCONC_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.000000</td>\n",
       "      <td>9032.00000</td>\n",
       "      <td>9032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4938.589460</td>\n",
       "      <td>1.958924</td>\n",
       "      <td>7.981842</td>\n",
       "      <td>7.978299</td>\n",
       "      <td>3.007418</td>\n",
       "      <td>2.496678</td>\n",
       "      <td>2.503432</td>\n",
       "      <td>0.249302</td>\n",
       "      <td>8.002214</td>\n",
       "      <td>7.948406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224092</td>\n",
       "      <td>0.624004</td>\n",
       "      <td>0.176705</td>\n",
       "      <td>0.327724</td>\n",
       "      <td>0.260850</td>\n",
       "      <td>0.735607</td>\n",
       "      <td>0.323295</td>\n",
       "      <td>0.643047</td>\n",
       "      <td>0.44597</td>\n",
       "      <td>0.370682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2798.272394</td>\n",
       "      <td>0.813718</td>\n",
       "      <td>4.945691</td>\n",
       "      <td>4.966099</td>\n",
       "      <td>1.581524</td>\n",
       "      <td>1.121651</td>\n",
       "      <td>1.112332</td>\n",
       "      <td>0.111112</td>\n",
       "      <td>4.939272</td>\n",
       "      <td>4.931868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.484406</td>\n",
       "      <td>0.381440</td>\n",
       "      <td>0.469409</td>\n",
       "      <td>0.439123</td>\n",
       "      <td>0.441034</td>\n",
       "      <td>0.467760</td>\n",
       "      <td>0.479127</td>\n",
       "      <td>0.49710</td>\n",
       "      <td>0.483014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2535.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5032.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7335.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9813.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID       CHOICE      STORES1   TRANSPORT1        CITY1  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000   \n",
       "mean   4938.589460     1.958924     7.981842     7.978299     3.007418   \n",
       "std    2798.272394     0.813718     4.945691     4.966099     1.581524   \n",
       "min       2.000000     1.000000     2.000000     2.000000     1.000000   \n",
       "25%    2535.000000     1.000000     5.000000     2.000000     2.000000   \n",
       "50%    5032.500000     2.000000     5.000000     5.000000     4.000000   \n",
       "75%    7335.000000     3.000000    10.000000    15.000000     5.000000   \n",
       "max    9813.000000     3.000000    15.000000    15.000000     5.000000   \n",
       "\n",
       "            NOISE1       GREEN1     FOREIGN1      STORES2   TRANSPORT2  ...  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000  ...   \n",
       "mean      2.496678     2.503432     0.249302     8.002214     7.948406  ...   \n",
       "std       1.121651     1.112332     0.111112     4.939272     4.931868  ...   \n",
       "min       1.000000     1.000000     0.100000     2.000000     2.000000  ...   \n",
       "25%       1.000000     2.000000     0.200000     5.000000     2.000000  ...   \n",
       "50%       3.000000     3.000000     0.200000    10.000000     5.000000  ...   \n",
       "75%       4.000000     3.000000     0.300000    10.000000    10.000000  ...   \n",
       "max       4.000000     4.000000     0.400000    15.000000    15.000000  ...   \n",
       "\n",
       "       HOMEOWNER_1   CAROWNER_1   RESPCITY_2   RESPCITY_3   RESPCITY_4  \\\n",
       "count  9032.000000  9032.000000  9032.000000  9032.000000  9032.000000   \n",
       "mean      0.224092     0.624004     0.176705     0.327724     0.260850   \n",
       "std       0.417006     0.484406     0.381440     0.469409     0.439123   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             JOB_1   EDUYEARS_2   EDUYEARS_3   ENVCONC_2    ENVCONC_3  \n",
       "count  9032.000000  9032.000000  9032.000000  9032.00000  9032.000000  \n",
       "mean      0.735607     0.323295     0.643047     0.44597     0.370682  \n",
       "std       0.441034     0.467760     0.479127     0.49710     0.483014  \n",
       "min       0.000000     0.000000     0.000000     0.00000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.00000     0.000000  \n",
       "50%       1.000000     0.000000     1.000000     0.00000     0.000000  \n",
       "75%       1.000000     1.000000     1.000000     1.00000     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.00000     1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenar las variables socio demográficas con las características relevantes de las alternativas\n",
    "dff = pd.concat([dff[['ID', 'CHOICE'] + attributes], df_sociovars], axis=1)\n",
    "\n",
    "print(dff.shape)\n",
    "dff.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Dividir los datos en un conjunto de entrenamiento y otro de test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de individuos en df_train y df_test: \t1832  426 \n",
      "Número de observaciones en df_train y df_test: \t7328 1704 \n"
     ]
    }
   ],
   "source": [
    "# Fijar una semilla para la reproducibilidad\n",
    "np.random.seed(100)\n",
    "dff['draw']=float('nan')\n",
    "for i in dff['ID'].unique():\n",
    "    num_obs = len(dff.loc[dff['ID']==i,'draw'])\n",
    "    dff.loc[dff['ID']==i,'draw']= np.repeat(np.random.uniform(0,1,1),num_obs)\n",
    "\n",
    "# Poner el 80% de los datos en el conjunto de entrenamiento y el 20% en el conjunto de prueba\n",
    "df_train = dff.loc[dff['draw']< 0.8,:].copy()\n",
    "df_test  = dff.loc[dff['draw']>=0.8,:].copy()\n",
    "\n",
    "# Número de observaciones en los conjuntos de entrenamiento y prueba\n",
    "num_obs_train = len(df_train)\n",
    "num_obs_test  = len(df_test)\n",
    "\n",
    "print(f'Número de individuos en df_train y df_test: \\t{df_train.ID.nunique()}  {df_test.ID.nunique()} ')\n",
    "print(f'Número de observaciones en df_train y df_test: \\t{len(df_train)} {len(df_test)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Escalar las características`<br>\n",
    "Para entrenar RNA de forma eficiente, se recomienda escalar (es decir, normalizar) las características. Existen varias formas de escalar los datos. A menudo se utiliza un escalador de sk-learn llamado 'StandardScaler'. Este escalador normaliza la varianza y desplaza la ubicación de la distribución a cero, vea https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de x_train (7328, 31)\n",
      "Dimensión de x_test (1704, 31)\n"
     ]
    }
   ],
   "source": [
    "# Crear X_train y X_test\n",
    "x_train = df_train[attributes + features_socio]\n",
    "x_test  = df_test [attributes + features_socio]\n",
    "\n",
    "# Inicializar el objeto scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar y transformar los datos de entrenamiento\n",
    "scaler = scaler.fit(dff[attributes + features_socio])\n",
    "\n",
    "# Aplicar el escalador ajustado a los conjuntos de datos\n",
    "x_train_scaled = pd.DataFrame(scaler.transform(df_train[attributes + features_socio]), columns=[attributes + features_socio])\n",
    "x_test_scaled =  pd.DataFrame(scaler.transform(df_test [attributes + features_socio]), columns=[attributes + features_socio]) \n",
    "\n",
    "print('Dimensión de x_train', x_train_scaled.shape)\n",
    "print('Dimensión de x_test', x_test_scaled.shape)\n",
    "\n",
    "# Crear valores de etiquetas \n",
    "# Y debe ser una matriz codificada como dummies\n",
    "y_train_dummy = pd.get_dummies(df_train['CHOICE']).values.astype(int)\n",
    "y_test_dummy = pd.get_dummies(df_test['CHOICE']).values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Convertir a tensores`<br>\n",
    "Muchos paquetes de machine learning trabajan con los llamados tensores. Los tensores son estructuras de datos dedicadas a entrenar eficientemente redes neuronales. Por tanto, necesitamos convertir las características y el etiqueta en un tipo de datos tensores. En PyTorch, esto se hace con `torch.tensor()`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de x_train_tensor\t torch.Size([7328, 18])\n",
      "Dimensión de x_test_tensor\t torch.Size([1704, 18])\n"
     ]
    }
   ],
   "source": [
    "# Crear tensores para el conjunto de entrenamiento\n",
    "# En este caso, usamos sólo las características de las alternativas 'features_alt'\n",
    "x_train_tensor = torch.tensor(x_train_scaled[attributes].values, dtype=torch.float)\n",
    "y_train_dummy_tensor = torch.tensor(y_train_dummy, dtype=torch.float)\n",
    "\n",
    "# Crear tensores para el conjunto de test\n",
    "x_test_tensor = torch.tensor(x_test_scaled[attributes].values, dtype=torch.float)\n",
    "y_test_dummy_tensor = torch.tensor(y_test_dummy, dtype=torch.float)\n",
    "\n",
    "print('Dimensión de x_train_tensor\\t', x_train_tensor.shape)\n",
    "print('Dimensión de x_test_tensor\\t', x_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `2. Estimación de un modelo de benchmark RUM-MNL lineal aditivo` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Estimación del modelo`<br>\n",
    "Primero estimamos nuestro modelo de benchmark RUM-MNL lineal-aditivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "biodata_train = db.Database('neighbourhood_data_train', df_train)\n",
    "\n",
    "STORES1     = Variable('STORES1')\n",
    "TRANSPORT1  = Variable('TRANSPORT1')\n",
    "CITY1       = Variable('CITY1')\n",
    "NOISE1      = Variable('NOISE1')\n",
    "GREEN1      = Variable('GREEN1')\n",
    "FOREIGN1    = Variable('FOREIGN1')\n",
    "\n",
    "STORES2     = Variable('STORES2')\n",
    "TRANSPORT2  = Variable('TRANSPORT2')\n",
    "CITY2       = Variable('CITY2')\n",
    "NOISE2      = Variable('NOISE2')\n",
    "GREEN2      = Variable('GREEN2')\n",
    "FOREIGN2    = Variable('FOREIGN2')\n",
    "    \n",
    "STORES3     = Variable('STORES3')\n",
    "TRANSPORT3  = Variable('TRANSPORT3')\n",
    "CITY3       = Variable('CITY3')\n",
    "NOISE3      = Variable('NOISE3')\n",
    "GREEN3      = Variable('GREEN3')\n",
    "FOREIGN3    = Variable('FOREIGN3')\n",
    "\n",
    "CHOICE      = Variable('CHOICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model Linear-additive RUM-MNL\n",
      "Nbr of parameters:\t\t6\n",
      "Sample size:\t\t\t7328\n",
      "Excluded data:\t\t\t0\n",
      "Null log likelihood:\t\t-8050.631\n",
      "Final log likelihood:\t\t-6471.391\n",
      "Likelihood ratio test (null):\t\t3158.48\n",
      "Rho square (null):\t\t\t0.196\n",
      "Rho bar square (null):\t\t\t0.195\n",
      "Akaike Information Criterion:\t12954.78\n",
      "Bayesian Information Criterion:\t12996.18\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Rob. Std err</th>\n",
       "      <th>Rob. t-test</th>\n",
       "      <th>Rob. p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B_city</th>\n",
       "      <td>-0.170377</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>-18.468215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_foreign</th>\n",
       "      <td>-1.193204</td>\n",
       "      <td>0.125067</td>\n",
       "      <td>-9.540546</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_green</th>\n",
       "      <td>0.416362</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>31.849350</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_noise</th>\n",
       "      <td>-0.448441</td>\n",
       "      <td>0.012045</td>\n",
       "      <td>-37.230843</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_stores</th>\n",
       "      <td>-0.036265</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>-12.193653</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_transport</th>\n",
       "      <td>-0.076922</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>-27.095476</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
       "B_city      -0.170377      0.009225   -18.468215           0.0\n",
       "B_foreign   -1.193204      0.125067    -9.540546           0.0\n",
       "B_green      0.416362      0.013073    31.849350           0.0\n",
       "B_noise     -0.448441      0.012045   -37.230843           0.0\n",
       "B_stores    -0.036265      0.002974   -12.193653           0.0\n",
       "B_transport -0.076922      0.002839   -27.095476           0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'Linear-additive RUM-MNL'\n",
    "\n",
    "B_stores    = Beta('B_stores'   , 0, None, None, 0)\n",
    "B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "B_city      = Beta('B_city'     , 0, None, None, 0)\n",
    "B_noise     = Beta('B_noise'    , 0, None, None, 0)\n",
    "B_green     = Beta('B_green'    , 0, None, None, 0)\n",
    "B_foreign   = Beta('B_foreign'  , 0, None, None, 0)\n",
    "\n",
    "V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3\n",
    "\n",
    "V  = {1: V1, 2: V2, 3: V3}    \n",
    "AV = {1: 1, 2: 1, 3: 1} \n",
    "\n",
    "prob = models.logit(V, AV, CHOICE)\n",
    "\n",
    "biogeme = bio.BIOGEME(biodata_train, log(prob))\n",
    "\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "biogeme.calculateNullLoglikelihood(AV)\n",
    "results = biogeme.estimate()\n",
    "print(results.short_summary())\n",
    "\n",
    "beta_hat = results.getEstimatedParameters()\n",
    "beta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Calcular la LL del modelo estimado en el conjunto de pruebas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL MNL test: -1543.88\n"
     ]
    }
   ],
   "source": [
    "# Crear el objeto Biogeme para la base de datos de prueba\n",
    "biodate_test = db.Database('Neighbourhood_data_test', df_test)\n",
    "\n",
    "# Simular la probabilidad de eleccion considerando el modelo MNL en los datos de prueba\n",
    "dict2simulate = {'prob_chosen':prob}\n",
    "\n",
    "# Crear el objeto de simulacion y calcular las probabilidades\n",
    "biosim = bio.BIOGEME(biodate_test,dict2simulate)\n",
    "simulated_probs = biosim.simulate(theBetaValues=results.getBetaValues())\n",
    "\n",
    "# Calcular Calculate la LL del MNL en la base de datos de prueba\n",
    "LL_MNL_test = np.log(simulated_probs['prob_chosen']).sum()\n",
    "print(f'LL MNL test: {LL_MNL_test:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Ejercicio 1: Disposición a pagar por vivir mas cerca de los supermercados``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Calcule la disposición a pagar para reducir el número de minutos caminando hasta las tiendas de comestibles en un minuto, expresado en términos de minutos caminando hasta el transporte público. Usa la fórmula::<br><br>\n",
    "$WTP = \\frac{\\beta_{stores}}{\\beta_{transport}}$<br><br>\n",
    "`B` Interprete este resultado. ¿Qué encuentran más importante las personas; minutos caminando hasta los supermercados o minutos caminando hasta el transporte público?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añade tus respuestas aqui}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añade tu código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La disposición a pagar para reducir un minuto el tiempo que se tarda en ir caminando al supermercado es: 0.47 minutos caminando hasta el transporte público\n",
      "\n",
      "La distancia al transporte público es casi dos veces más importante que la distancia a los supermercados porque el WTP es < 1\n"
     ]
    }
   ],
   "source": [
    "# ANSWERS\n",
    "# A\n",
    "WTP_MNL = beta_hat.loc['B_stores']['Value']/beta_hat.loc['B_transport']['Value']\n",
    "print(f'\\nLa disposición a pagar para reducir un minuto el tiempo que se tarda en ir caminando al supermercado es: {WTP_MNL:.2f} minutos caminando hasta el transporte público')\n",
    "\n",
    "# B\n",
    "print('\\nLa distancia al transporte público es casi dos veces más importante que la distancia a los supermercados porque el WTP es < 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3. El modelo MLP`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A El perceptrón multicapa (MLP) es una red neuronal ampliamente utilizada en el machine learning por su capacidad para aprender patrones complejos. Está compuesto por capas ocultas con neuronas y funciones de activación. <br>\n",
    "\n",
    "Por ejemplo, en la siguiente imagen, podemos ver una capa de entrada con 8 características, dos capas ocultas con 10 nodos ocultos cada una, y la capa de salida con 3 clases de salida:<br>\n",
    "\n",
    "<p align=\"center\\\">\n",
    "<img width=\"800\" src=\"Assets/MLP.png\">\n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Definición del modelo MLP`<br>\n",
    "\n",
    "Crearemos una red neuronal totalmente conectada con dos capas ocultas. Para ello, crearemos una nueva clase utilizando el módulo nn.Module de PyTorch. \n",
    "\n",
    "En este caso, tendremos una capa de entrada de tamaño `input_size`, dos capas ocultas de tamaños `hidden_size1` y `hidden_size2` respectivamente, y una capa de salida de tamaño `output_size`. \n",
    "\n",
    "Además, definiremos la función de propragación. La función de propragación toma un valor de entrada `x`, lo pasa a través de las capas de la red, al tiempo que aplica funciones de activación. \n",
    "\n",
    "El resultado son las utilidades de cada alternativa `V`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red neuronal totalmente conectada con dos capas ocultas\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x)) # función de activación tanh para la 1 capa\n",
    "        x = torch.tanh(self.fc2(x)) # función de activación tanh para la 2 capa\n",
    "        V = self.fc3(x)             # función de activación lineal para la capa de salida\n",
    "\n",
    "        return V                    # devuelve la «Utilidad» de cada alternativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Creación de DataLoaders`<br>\n",
    "A través de un objeto PyTorch Dataloader se maneja eficientemente el flujo de datos durante el entrenamiento y las evaluaciones. Este crea mini lotes, y se asegura de que las instancias de los datos se utilicen en cada época. <br>\n",
    "\n",
    "Crearemos un DataLoader para los conjuntos de datos de entrenamiento y prueba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataLoader para el conjunto de entrenamientos\n",
    "dataset_train = TensorDataset(x_train_tensor, y_train_dummy_tensor)\n",
    "train_loader = DataLoader(dataset_train, batch_size=250, shuffle=True)\n",
    "\n",
    "# Crear un DataLoader para el conjunto de pruebas\n",
    "dataset_test = TensorDataset(x_test_tensor, y_test_dummy_tensor)\n",
    "test_loader = DataLoader(dataset_test, batch_size=len(x_test_tensor), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Definir funciones`<br>\n",
    "Definiremos las siguientes funciones:\n",
    "1. Una función para evaluar el rendimiento del modelo durante el entrenamiento.\n",
    "2. Una función para visualizar el progreso del entrenamiento.\n",
    "3. Una función para examinar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, data_loader):\n",
    "    model.eval()  # Poner el modelo en modo evaluación\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función visualiza el progreso del entrenamiento. Llamamos a esta función una vez finalizado el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss_plot(train_losses, test_losses, num_obs_train, num_obs_test):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(np.array(train_losses)/num_obs_train, label='Training Loss')\n",
    "    ax.plot(np.array(test_losses)/num_obs_test,   label='Test Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función nos permite inspeccionar la arquitectura del modelo creado. Enumera el número de pesos por capa y sus tamaños de entrada y salida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_summary(model):\n",
    "    total_params = 0\n",
    "    print(f\"=== Model Summary ===\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params = param.numel()\n",
    "            total_params += num_params\n",
    "            print(f\"Layer: {name:20}|\\t Weights: {num_params}\")\n",
    "\n",
    "    print(f\"\\nTotal trainable Weights: {total_params}\")\n",
    "\n",
    "    print(\"\\n=== Layers ===\")\n",
    "    for layer in model.children():\n",
    "        print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Crear el objeto MLP`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_size = 18, hidden_size1 = 10, hidden_size2 = 10, output_size = 3\n"
     ]
    }
   ],
   "source": [
    "# Definir las dimensiones del MLP\n",
    "input_size   = x_train_tensor.size()[1]  # Número de características de entrada\n",
    "hidden_size1 = 10                        # Número de nodos en la primera capa oculta\n",
    "hidden_size2 = 10                        # Número de nodos en la primera capa oculta\n",
    "output_size  = 3                         # Número de clases (determinado por el numero de alternativas)\n",
    "print(f' input_size = {input_size}, hidden_size1 = {hidden_size1}, hidden_size2 = {hidden_size2}, output_size = {output_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "Layer: fc1.weight          |\t Weights: 180\n",
      "Layer: fc1.bias            |\t Weights: 10\n",
      "Layer: fc2.weight          |\t Weights: 100\n",
      "Layer: fc2.bias            |\t Weights: 10\n",
      "Layer: fc3.weight          |\t Weights: 30\n",
      "Layer: fc3.bias            |\t Weights: 3\n",
      "\n",
      "Total trainable Weights: 333\n",
      "\n",
      "=== Layers ===\n",
      "Linear(in_features=18, out_features=10, bias=True)\n",
      "Linear(in_features=10, out_features=10, bias=True)\n",
      "Linear(in_features=10, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Invocar el modelo MLP\n",
    "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Mostrar la arquitectura del modelo\n",
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`v. Entrenar el modelo MLP`<br>\n",
    "Finalmente, ¡estamos listos para entrenar el modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpoch = 500 # Establecer el número de epochs\n",
    "lr = 0.0001 # Establecer la tasa de aprendizaje\n",
    "status = 10 # Imprimir estado cada 'status' épocas\n",
    "patience = 5 # Número de epochs a esperar antes de parar preventivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/500], Train Loss: 8276.667, Test Loss: 1907.639\n",
      "Epoch [   10/500], Train Loss: 7851.364, Test Loss: 1813.829\n",
      "Epoch [   20/500], Train Loss: 7428.162, Test Loss: 1722.638\n",
      "Epoch [   30/500], Train Loss: 7055.410, Test Loss: 1646.358\n",
      "Epoch [   40/500], Train Loss: 6739.162, Test Loss: 1585.970\n",
      "Epoch [   50/500], Train Loss: 6489.418, Test Loss: 1541.564\n",
      "Epoch [   60/500], Train Loss: 6319.984, Test Loss: 1513.048\n",
      "Epoch [   70/500], Train Loss: 6217.813, Test Loss: 1496.014\n",
      "Epoch [   80/500], Train Loss: 6158.208, Test Loss: 1485.112\n",
      "Epoch [   90/500], Train Loss: 6121.048, Test Loss: 1477.421\n",
      "Epoch [  100/500], Train Loss: 6096.684, Test Loss: 1471.862\n",
      "Epoch [  110/500], Train Loss: 6079.722, Test Loss: 1467.640\n",
      "Epoch [  120/500], Train Loss: 6067.304, Test Loss: 1464.320\n",
      "Epoch [  130/500], Train Loss: 6058.189, Test Loss: 1461.983\n",
      "Epoch [  140/500], Train Loss: 6051.103, Test Loss: 1459.989\n",
      "Epoch [  150/500], Train Loss: 6045.186, Test Loss: 1458.389\n",
      "Epoch [  160/500], Train Loss: 6040.724, Test Loss: 1457.189\n",
      "Epoch [  170/500], Train Loss: 6037.162, Test Loss: 1456.120\n",
      "Epoch [  180/500], Train Loss: 6033.773, Test Loss: 1455.136\n",
      "Epoch [  190/500], Train Loss: 6031.571, Test Loss: 1454.683\n",
      "Epoch [  200/500], Train Loss: 6029.047, Test Loss: 1453.600\n",
      "Epoch [  210/500], Train Loss: 6026.990, Test Loss: 1453.336\n",
      "Epoch [  220/500], Train Loss: 6025.369, Test Loss: 1452.992\n",
      "Epoch [  230/500], Train Loss: 6023.485, Test Loss: 1452.333\n",
      "Epoch [  240/500], Train Loss: 6022.025, Test Loss: 1451.902\n",
      "Epoch [  250/500], Train Loss: 6021.011, Test Loss: 1451.337\n",
      "Epoch [  260/500], Train Loss: 6019.594, Test Loss: 1451.186\n",
      "Parada anticipada en la epch 264\n",
      "\n",
      "Entrenamiento finalizado. \tPérdida de entrenamiento: 6019.190, Pérdida de test: 1451.071\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_training = True\n",
    "if do_training == True:\n",
    "\n",
    "    # Definir el modelo, la función de pérdida y el optimizador\n",
    "    \n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr,  betas=(0.9, 0.999), eps=1e-07, weight_decay=0)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    # Definir listas para almacenar los valores de loss \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # Inicializar el contador de parada anticipada \n",
    "    counter = 0\n",
    "    best_loss = np.inf  # Establece la pérdida inicial a infinito\n",
    "\n",
    "    # Bucle de entrenamiento\n",
    "    for epoch in range(nEpoch):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Poner a cero los gradientes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)   \n",
    "\n",
    "            # Calcular la perdida\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass y optimizacion\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Actualizar la pérdida\n",
    "            running_loss += loss.item() # Log-verosimilitud en el conjunto de entrenamiento\n",
    "\n",
    "        # Evaluar en el conjunto de prueba\n",
    "        test_loss = evaluate(model, loss_fn, test_loader) # Log-verosimilitud en el conjunto de prueba\n",
    "\n",
    "        \n",
    "        if epoch == 0 or (epoch + 1) % status == 0:\n",
    "            print(f'Epoch [{epoch+1:5.0f}/{nEpoch}], Train Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "\n",
    "        # Almacenar pérdidas\n",
    "        train_losses.append(running_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        # Implementar la parada anticipada\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Parada anticipada en la epch {epoch+1}')\n",
    "                break\n",
    "            \n",
    "    print(f'\\nEntrenamiento finalizado. \\tPérdida de entrenamiento: {running_loss:0.3f}, Pérdida de test: {test_loss:0.3f}')\n",
    "    show_loss_plot(train_losses, test_losses,num_obs_train, num_obs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Ejercicio 2: Entrenamiento del modelo MLP`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Compare el rendimiento en el conjunto de prueba del MLP con el MNL de referencia. ¿Ha mejorado (mucho)? ¿Qué nos dice esto? <br>\n",
    "`B` Reentrena el MLP utilizando las siguientes arquitecturas: {hidden_size1,hidden_size2} = {1,1}, {3,3}, {1,20}, {20,1}, {20,3}, {20,20}<br>\n",
    "`C` ¿El aumento del número de neuronas conduce a un mejor rendimiento de generalización (es decir, mayor LL_test)? ¿Qué ocurre?\n",
    "`D` Explique por qué {1,1} y {20,1} y {1,20} conducen a un rendimiento pobre. <br>\n",
    "`E` Reentrene su modelo con una tasa de aprendizaje menor y mayor: lr = 0,01 y lr = 0,00001. Use {hidden_size1,hidden_size2} = {5,5}. Explique lo que ocurre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Añada su código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPUESTAS\n",
    "#`A` El MLP mejora el ajuste del modelo en casi 100 puntos LL. Esto es mucho. Indica que el supuesto de utilidad lineal aditiva es demasiado restrictivo.\n",
    "\n",
    "#`B`\n",
    "#{1,1} da un pobre rendimiento de generalización: LL = ~-1590\n",
    "#{3,3} da un rendimiento de generalización aceptable: LL = ~-1400\n",
    "#{1,20} da un rendimiento de generalización deficiente: LL = ~-1500\n",
    "#{20,1} da un rendimiento de generalización deficiente: LL = ~-1500\n",
    "#{20,3} da un rendimiento de generalización aceptable: LL = ~-1400 \n",
    "\n",
    "#`C` El aumento de {1,1} a {3,3} aumentar el desempeño en LL_test. Pero {20,20} no ayuda a que aumente más. \n",
    "\n",
    "#`D` Toda la información es comprimida en un nodo. Por lo tanto, los modelos no son capaces de asociar características a alternativas, lo que lleva a un rendimiento pobre.\n",
    "\n",
    "#`E` Un lr grande lleva a un entrenamiento rápido. Pero inestabilidad cerca de la convergencia. Un lr pequeño conduce a un entrenamiento lento. El modelo no estaba cerca de la convergencia cuando se alcanzó el número máximo de épocas de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Ejercicio 3: Añadir las características sociodemográficas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la sección 1, en `iv. Convertir en tensores` decidimos utilizar sólo las características de las alternativas como entradas (es decir, `features_alt`), mientras que en la sesión de laboratorio 1 vimos que al menos el género (`WOMAN`) y la ciudad de residencia (`RESPCITY`) tienen cierto poder explicativo.<br>\n",
    "\n",
    "`A` Modifica el código en esta celda para que también se utilicen estas características socio demográficas. Después, vuelva a entrenar el MLP.\n",
    "`B` Quizás en contra de sus expectativas, el rendimiento del modelo no aumenta mucho. \n",
    "¿Qué nos dice esto sobre: \n",
    "1. el poder explicativo de las características sociodemográficas para la elección de la zona residencial, y \n",
    "2. la capacidad de los modelos MLP para aprender efectos de interacción sutiles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Añada su código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "do_exercise3 = False\n",
    "if do_exercise3 == True:\n",
    "    #### Recrear tensores para los datos de entrenamiento ####\n",
    "    features_alt = attributes\n",
    "    #En este caso, utilizamos las características de las alternativas 'features_alt', WOMAN y RESPCITY.\n",
    "    selected_features = features_alt + ['WOMAN_1', 'RESPCITY_2', 'RESPCITY_3', 'RESPCITY_4']\n",
    "\n",
    "    x_train_tensor = torch.tensor(x_train_scaled[selected_features].values, dtype=torch.float)\n",
    "    y_train_dummy_tensor = torch.tensor(y_train_dummy, dtype=torch.float)\n",
    "\n",
    "    x_test_tensor = torch.tensor(x_test_scaled[selected_features].values, dtype=torch.float)\n",
    "    y_test_dummy_tensor = torch.tensor(y_test_dummy, dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "    #### Recrear DataLoader ####\n",
    "    dataset_train = TensorDataset(x_train_tensor, y_train_dummy_tensor)\n",
    "    train_loader = DataLoader(dataset_train, batch_size=250, shuffle=True)\n",
    "\n",
    "    dataset_test = TensorDataset(x_test_tensor, y_test_dummy_tensor)\n",
    "    test_loader = DataLoader(dataset_test, batch_size=len(x_test_tensor), shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "    #### Redefinir la dimension de MLP  ####\n",
    "    input_size   = x_train_tensor.size()[1]  \n",
    "    hidden_size1 = 20                        \n",
    "    hidden_size2 = 20                        \n",
    "    output_size  = 3                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4. El modelo L-MNL `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, construiremos y entrenaremos un modelo híbrido, concretamente el modelo L-MNL. Este modelo combina una parte interpretable siguiendo los supuestos del modelo MNL y una red neuronal que procesa el resto de variables que no queremos interpretar. Más concretamente, queremos la **flexibilidad** del MLP pero aún así queremos obtener una **estimación de la disposición a pagar por reducir el tiempo de caminata a los supermercados, expresada en términos del tiempo al transporte público**.\n",
    "\n",
    "La figura siguiente muestra conceptualmente este modelo:<br>\n",
    "\n",
    "<p align=\"center\">\n",
    "<img width=\"600\" src=\"assets/hybrid_model.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Definir el modelo L-MNL`<br>\n",
    "Para crear el modelo L-MNL,creamos una nueva clase utilizando nn.Module de PyTorch. <br>\n",
    "* La parte MNL se implementa con capas lineales separadas para las características («transport» y «foreign»), permitiendo calcular la utilidad para cada alternativa. <br>\n",
    "* La parte MLP consiste en dos capas ocultas (linear1 y linear2) con un número dado de neuronas.<br>\n",
    "* La función forward toma `x_mnl` y `x_mlp` como entradas. x_mlp se pasa a través de las capas de la red (`V_MLP`), mientras que x_mnl se utiliza para calcular las utilidades de forma lineal aditiva (`V_MNL`). \n",
    "* Finalmente, se suman las utilidades de ambas partes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMNL(nn.Module):\n",
    "    def __init__(self, input_size_mlp, hidden_size1, hidden_size2,output_size):\n",
    "        super(LMNL,self).__init__()\n",
    "\n",
    "        # Crear betas para la parte MNL\n",
    "        self.B_transport = nn.Linear(1, 1, bias=False )\n",
    "        self.B_stores   = nn.Linear(1, 1, bias=False )\n",
    "                                 \n",
    "        # Crear las capas ocultas para la parte MLP \n",
    "        self.linear1 = nn.Linear(input_size_mlp, hidden_size1, bias=False)\n",
    "        self.linear2 = nn.Linear(hidden_size1,   hidden_size2, bias=False) \n",
    "        self.linear3 = nn.Linear(hidden_size2,   output_size,  bias=False) \n",
    "\n",
    "    def forward(self, X_MNL, X_MLP):\n",
    "        \n",
    "        # Funcion de utilidad para la parte MNL \n",
    "        V_A = self.B_transport(X_MNL[:,0].unsqueeze(1))  + self.B_stores(X_MNL[:,1].unsqueeze(1))\n",
    "        V_B = self.B_transport(X_MNL[:,2].unsqueeze(1))  + self.B_stores(X_MNL[:,3].unsqueeze(1))\n",
    "        V_C = self.B_transport(X_MNL[:,4].unsqueeze(1))  + self.B_stores(X_MNL[:,5].unsqueeze(1))\n",
    "                     \n",
    "        # Concatenating tensors to maintain the output dimension\n",
    "        V_MNL = torch.cat((V_A, V_B, V_C), dim=1)\n",
    "\n",
    "        # La parte MLP\n",
    "        X_MLP = torch.tanh(self.linear1(X_MLP)) \n",
    "        X_MLP = torch.tanh(self.linear2(X_MLP)) \n",
    "        V_MLP = self.linear3(X_MLP)             \n",
    "\n",
    "        V = V_MNL + V_MLP\n",
    "        return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Preparar los datos para entrenar el modelo L-MNL`<br>\n",
    "\n",
    "Necesitamos dividir las características que van en las partes MLP y MNL. Porque queremos calcular la WTP de los supermercados sobre el transporte. Por lo tanto, las características relacionadas con el transporte y las tiendas van a la parte MNL, mientras que las demás características, incluidas las sociodemográficas, van a la parte MLP.\n",
    "\n",
    " **Importante**, las características MNL NO deben escalarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimesión de x_mnl_train\t (7328, 6)\n",
      "Dimesión de x_mnl_test\t (1704, 6)\n",
      "\n",
      "Dimesión de x_mlp_train\t (7328, 15)\n",
      "Dimesión de x_mlp_test\t (1704, 15)\n"
     ]
    }
   ],
   "source": [
    "features_mnl = ['TRANSPORT1', 'STORES1','TRANSPORT2', 'STORES2','TRANSPORT3', 'STORES3']\n",
    "x_mnl_train = x_train[features_mnl]\n",
    "x_mnl_test  = x_test[features_mnl]\n",
    "\n",
    "print('Dimesión de x_mnl_train\\t', x_mnl_train.shape)\n",
    "print('Dimesión de x_mnl_test\\t', x_mnl_test.shape)\n",
    "\n",
    "features_mlp_alt = ['FOREIGN1', 'CITY1', 'NOISE1', 'GREEN1', \n",
    "                    'FOREIGN2', 'CITY2', 'NOISE2', 'GREEN2', \n",
    "                    'FOREIGN3', 'CITY3', 'NOISE3', 'GREEN3']\n",
    "\n",
    "\n",
    "features_socio = ['RESPCITY_2','RESPCITY_3','RESPCITY_4']\n",
    "x_mlp_train = x_train_scaled[features_mlp_alt + features_socio]\n",
    "x_mlp_test  = x_test_scaled[features_mlp_alt + features_socio]\n",
    "\n",
    "print('\\nDimesión de x_mlp_train\\t', x_mlp_train.shape)\n",
    "print('Dimesión de x_mlp_test\\t', x_mlp_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir datos en tensores PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del tensor X_mnl_train =  torch.Size([7328, 6])\n",
      "Tamaño del tensor X_mlp_train =  torch.Size([7328, 15])\n",
      "\n",
      "Tamaño del tensorX_mnl_test  =  torch.Size([1704, 6])\n",
      "Tamaño del tensor X_mlp_test  =  torch.Size([1704, 15])\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "x_mnl_train_tensor = torch.tensor(x_mnl_train.values, dtype=torch.float)\n",
    "x_mlp_train_tensor = torch.tensor(x_mlp_train.values, dtype=torch.float)\n",
    "y_train_dummy_tensor = torch.tensor(y_train_dummy,    dtype=torch.float)\n",
    "\n",
    "# test\n",
    "x_mnl_test_tensor = torch.tensor(x_mnl_test.values, dtype=torch.float)\n",
    "x_mlp_test_tensor = torch.tensor(x_mlp_test.values, dtype=torch.float)\n",
    "y_test_dummy_tensor = torch.tensor(y_test_dummy,    dtype=torch.float)\n",
    "\n",
    "print('Tamaño del tensor X_mnl_train = ', x_mnl_train_tensor.size())\n",
    "print('Tamaño del tensor X_mlp_train = ', x_mlp_train_tensor.size())\n",
    "print('\\nTamaño del tensorX_mnl_test  = ', x_mnl_test_tensor.size())\n",
    "print('Tamaño del tensor X_mlp_test  = ', x_mlp_test_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataLoader para el conjunto de entrenamiento\n",
    "dataset_train_lmnl = TensorDataset(x_mnl_train_tensor, x_mlp_train_tensor, y_train_dummy_tensor)\n",
    "train_loader_lmnl = DataLoader(dataset_train_lmnl, batch_size=250, shuffle=True)\n",
    "\n",
    "# Crear un DataLoader para el conjunto de test\n",
    "dataset_test_lmnl = TensorDataset(x_mnl_test_tensor, x_mlp_test_tensor, y_test_dummy_tensor)\n",
    "test_loader_lmnl = DataLoader(dataset_test_lmnl, batch_size=len(x_test_tensor), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Definir funciones`<br>\n",
    "No podemos reutilizar la función de evaluación que creamos antes, porque este modelo toma dos entradas (x_mnl, x_mlp), en lugar de una. Por lo tanto, creamos una nueva para el modelo L-MNL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lmnl(model, criterion, data_loader):\n",
    "    model.eval()  \n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_mnl, x_mlp, labels in data_loader:\n",
    "            outputs = model(x_mnl,x_mlp)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Create the L-MNL model object`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_size_mnl = 6, input_size_mlp = 15, hidden_size1 = 10, hidden_size2 = 10, output_size = 3\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "input_size_mnl = x_mnl_train_tensor.size()[1]  \n",
    "input_size_mlp = x_mlp_train_tensor.size()[1]  \n",
    "hidden_size1 = 10  \n",
    "hidden_size2 = 10  \n",
    "output_size = 3    \n",
    "print(f' input_size_mnl = {input_size_mnl}, input_size_mlp = {input_size_mlp}, hidden_size1 = {hidden_size1}, hidden_size2 = {hidden_size2}, output_size = {output_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "Layer: B_transport.weight  |\t Weights: 1\n",
      "Layer: B_stores.weight     |\t Weights: 1\n",
      "Layer: linear1.weight      |\t Weights: 150\n",
      "Layer: linear2.weight      |\t Weights: 100\n",
      "Layer: linear3.weight      |\t Weights: 30\n",
      "\n",
      "Total trainable Weights: 282\n",
      "\n",
      "=== Layers ===\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Linear(in_features=15, out_features=10, bias=False)\n",
      "Linear(in_features=10, out_features=10, bias=False)\n",
      "Linear(in_features=10, out_features=3, bias=False)\n"
     ]
    }
   ],
   "source": [
    "# Invocar al modelo L-MNL\n",
    "model = LMNL(input_size_mlp, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`v. Entrenar el modelo L-MNL`<br>\n",
    "Finalmente, ¡estamos listos para entrenar el modelo L-MNL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpoch = 1000  \n",
    "lr = 0.0001  \n",
    "status = 10  \n",
    "patience = 5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/1000], Train Loss: 20734.998, Test Loss: 4863.703\n",
      "Epoch [   10/1000], Train Loss: 19650.273, Test Loss: 4616.312\n",
      "Epoch [   20/1000], Train Loss: 18286.001, Test Loss: 4304.731\n",
      "Epoch [   30/1000], Train Loss: 16663.796, Test Loss: 3936.127\n",
      "Epoch [   40/1000], Train Loss: 14919.554, Test Loss: 3540.859\n",
      "Epoch [   50/1000], Train Loss: 13272.279, Test Loss: 3164.543\n",
      "Epoch [   60/1000], Train Loss: 11863.274, Test Loss: 2838.761\n",
      "Epoch [   70/1000], Train Loss: 10692.951, Test Loss: 2567.238\n",
      "Epoch [   80/1000], Train Loss: 9718.844, Test Loss: 2341.505\n",
      "Epoch [   90/1000], Train Loss: 8917.934, Test Loss: 2156.332\n",
      "Epoch [  100/1000], Train Loss: 8282.631, Test Loss: 2010.111\n",
      "Epoch [  110/1000], Train Loss: 7797.149, Test Loss: 1899.218\n",
      "Epoch [  120/1000], Train Loss: 7435.375, Test Loss: 1816.507\n",
      "Epoch [  130/1000], Train Loss: 7165.360, Test Loss: 1754.613\n",
      "Epoch [  140/1000], Train Loss: 6960.700, Test Loss: 1706.998\n",
      "Epoch [  150/1000], Train Loss: 6800.742, Test Loss: 1668.449\n",
      "Epoch [  160/1000], Train Loss: 6670.627, Test Loss: 1636.132\n",
      "Epoch [  170/1000], Train Loss: 6561.472, Test Loss: 1607.881\n",
      "Epoch [  180/1000], Train Loss: 6467.879, Test Loss: 1582.943\n",
      "Epoch [  190/1000], Train Loss: 6387.913, Test Loss: 1560.955\n",
      "Epoch [  200/1000], Train Loss: 6319.947, Test Loss: 1542.022\n",
      "Epoch [  210/1000], Train Loss: 6263.544, Test Loss: 1525.677\n",
      "Epoch [  220/1000], Train Loss: 6216.978, Test Loss: 1512.167\n",
      "Epoch [  230/1000], Train Loss: 6179.431, Test Loss: 1500.657\n",
      "Epoch [  240/1000], Train Loss: 6149.853, Test Loss: 1491.522\n",
      "Epoch [  250/1000], Train Loss: 6126.485, Test Loss: 1483.996\n",
      "Epoch [  260/1000], Train Loss: 6108.030, Test Loss: 1477.918\n",
      "Epoch [  270/1000], Train Loss: 6093.743, Test Loss: 1473.016\n",
      "Epoch [  280/1000], Train Loss: 6082.323, Test Loss: 1469.139\n",
      "Epoch [  290/1000], Train Loss: 6073.056, Test Loss: 1466.099\n",
      "Epoch [  300/1000], Train Loss: 6065.383, Test Loss: 1463.317\n",
      "Epoch [  310/1000], Train Loss: 6058.769, Test Loss: 1461.248\n",
      "Epoch [  320/1000], Train Loss: 6053.140, Test Loss: 1459.528\n",
      "Epoch [  330/1000], Train Loss: 6048.303, Test Loss: 1457.872\n",
      "Epoch [  340/1000], Train Loss: 6043.559, Test Loss: 1456.547\n",
      "Epoch [  350/1000], Train Loss: 6039.417, Test Loss: 1455.367\n",
      "Epoch [  360/1000], Train Loss: 6035.456, Test Loss: 1454.368\n",
      "Epoch [  370/1000], Train Loss: 6031.850, Test Loss: 1453.265\n",
      "Epoch [  380/1000], Train Loss: 6028.491, Test Loss: 1452.451\n",
      "Epoch [  390/1000], Train Loss: 6025.297, Test Loss: 1451.599\n",
      "Epoch [  400/1000], Train Loss: 6022.458, Test Loss: 1450.945\n",
      "Epoch [  410/1000], Train Loss: 6019.133, Test Loss: 1450.272\n",
      "Epoch [  420/1000], Train Loss: 6016.464, Test Loss: 1449.711\n",
      "Epoch [  430/1000], Train Loss: 6014.003, Test Loss: 1449.061\n",
      "Epoch [  440/1000], Train Loss: 6011.400, Test Loss: 1448.503\n",
      "Epoch [  450/1000], Train Loss: 6008.841, Test Loss: 1448.258\n",
      "Epoch [  460/1000], Train Loss: 6006.409, Test Loss: 1447.693\n",
      "Epoch [  470/1000], Train Loss: 6004.382, Test Loss: 1447.312\n",
      "Epoch [  480/1000], Train Loss: 6002.124, Test Loss: 1447.068\n",
      "Epoch [  490/1000], Train Loss: 6000.073, Test Loss: 1446.634\n",
      "Epoch [  500/1000], Train Loss: 5998.011, Test Loss: 1446.449\n",
      "Epoch [  510/1000], Train Loss: 5996.237, Test Loss: 1446.012\n",
      "Epoch [  520/1000], Train Loss: 5994.261, Test Loss: 1445.757\n",
      "Parada anticipada en la época 523\n",
      "\n",
      "Entrenamiento terminado.\tPérdida de entrenamiento: 5993.721, Pérdida de test: 1445.863\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir la función de pérdida y el optimizador\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr,  betas=(0.9, 0.999), eps=1e-07, weight_decay=0)\n",
    "\n",
    "# Definir las listas para almacenar las pérdidas\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Inicializar contador de parada anticipada \n",
    "counter = 0\n",
    "best_loss = np.inf  # Establecer la pérdida inicial a infinito\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(nEpoch):\n",
    "    running_loss = 0.0\n",
    "    for x_mnl, x_mlp, labels in train_loader_lmnl:\n",
    "        \n",
    "        # Poner a cero los gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_mnl,x_mlp)   \n",
    "\n",
    "        # Calcular la perdida\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass y optimizacion\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() # Log-verosimilitud en el conjunto de entrenamiento\n",
    "\n",
    "    # Evaluar en el conjunto de prueba\n",
    "    test_loss = evaluate_lmnl(model, loss_fn, test_loader_lmnl)\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % status == 0:\n",
    "        print(f'Epoch [{epoch+1:5.0f}/{nEpoch}], Train Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "\n",
    "    train_losses.append(running_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Implementar la parada anticipada\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Parada anticipada en la época {epoch+1}')\n",
    "            break\n",
    "        \n",
    "print(f'\\nEntrenamiento terminado.\\tPérdida de entrenamiento: {running_loss:0.3f}, Pérdida de test: {test_loss:0.3f}')\n",
    "show_loss_plot(train_losses, test_losses, num_obs_train, num_obs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La disposición a pagar para reducir un minuto el tiempo de caminata hasta el supermercado es: 0.91 minutos caminando hasta el transporte público\n"
     ]
    }
   ],
   "source": [
    "# Calcular la disposición a pagar para reducir el tiempo caminado al supermercado en un minuto\n",
    "LL_LMNL = best_loss\n",
    "B_transport_LMNL = model.B_transport.weight.data.item()\n",
    "B_stores_LMNL = model.B_stores.weight.data.item()\n",
    "\n",
    "WTP_LMNL = B_stores_LMNL/B_transport_LMNL\n",
    "print(f'\\nLa disposición a pagar para reducir un minuto el tiempo de caminata hasta el supermercado es: {WTP_LMNL:.2f} minutos caminando hasta el transporte público')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Reflexiones`\n",
    "1. El modelo L-MNL consigue un ajuste del modelo muy próximo al modelo MLP totalmente flexible\n",
    "1. El modelo L-MNL permite comprender la relación entre la distancia a los supermercados y la distancia al transporte público.\n",
    "1. Los resultados recuperan que la WTP no es estable, sino que fluctúa a lo largo de los entrenamientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Ejercicio 4: Características L-MLP`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Pruebe a reducir el número de características que se introducen en el MLP y evalúe el impacto en el rendimiento del modelo y la WTP. Es decir, utilice sólo «RESPCITY» y «WOMAN»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añade tu código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_exercise4 = False\n",
    "if do_exercise4 == True:\n",
    "    \n",
    "    features_socio = ['WOMAN_1', 'RESPCITY_2', 'RESPCITY_3', 'RESPCITY_4']\n",
    "\n",
    "    x_mlp_train = x_train_scaled[features_mlp_alt + features_socio]\n",
    "    x_mlp_test  = x_test_scaled[features_mlp_alt + features_socio]\n",
    "    \n",
    "    x_mlp_train_tensor = torch.tensor(x_mlp_train.values, dtype=torch.float)\n",
    "    x_mlp_test_tensor = torch.tensor(x_mlp_test.values, dtype=torch.float)\n",
    "    \n",
    "\n",
    "    dataset_train_lmnl = TensorDataset(x_mnl_train_tensor, x_mlp_train_tensor, y_train_dummy_tensor)\n",
    "    train_loader_lmnl = DataLoader(dataset_train_lmnl, batch_size=250, shuffle=True)\n",
    "    dataset_test_lmnl = TensorDataset(x_mnl_test_tensor, x_mlp_test_tensor, y_test_dummy_tensor)\n",
    "    test_loader_lmnl = DataLoader(dataset_test_lmnl, batch_size=len(x_test_tensor), shuffle=False)\n",
    "\n",
    "\n",
    "    input_size_mlp = x_mlp_train_tensor.size()[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A.ii` Volver a entrenar el modelo MLP utilizando la celda anterior:  <br>\n",
    "\n",
    "Pérdida de entrenamiento: 6019,589, Pérdida de test: 1378,459 y la Disposición a pagar por reducir un minuto el tiempo de caminata hasta los supermercados es: 1,02 minutos de caminata hasta el transporte público."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Ejercicio 5: Predicción utilizando L-MNL`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un investigador desearía utilizar este modelo para hacer predicciones sobre la cuota de mercado. Sin embargo, esto es más difícil.<br>\n",
    "\n",
    "`A` Explique 2 razones por las que realizar previsiones con el modelo L-MNL es menos sencillo que con los modelos MNL.<br>\n",
    "`B` Explique 2 argumentos a favor de la utilización del modelo L-MNL como base para la elaboración de políticas.<br>\n",
    "`C` Supongamos que le contratan para ayudar y asesorar a este investigador. ¿Qué le aconsejaría, por ejemplo, en cuanto a la especificación del modelo L-MNL, la formación, la evaluación comparativa, etc.?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añade tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` <br>\n",
    "(1) El modelo hace predicciones diferentes cada vez que lo entrenamos. Para tener esto en cuenta, el investigador probablemente deba entrenar varios modelos y promediar las predicciones.<br>\n",
    "(2) En caso de que se utilicen variables sociodemográficas, las predicciones del modelo L-MNL son condicionales a las variables sociodemográficas. En caso de que la muestra esté sesgada (por ejemplo, demasiadas mujeres/jóvenes, etc., no está claro cómo corregirlo).<br>\n",
    "(3) Los tiempos de entrenamiento y el preprocesamiento de datos son más largos y laboriosos<br>\n",
    "(4) El modelo es menos fácil de explicar a los no especialistas que un simple modelo MNL. Por ejemplo, los responsables políticos son reacios a basar sus decisiones en modelos que no comprenden.<br>\n",
    "\n",
    "`B` <br>\n",
    "(1) Empíricamente, el modelo L-MNL consigue un ajuste considerablemente mejor. Esto significa que el modelo es capaz de replicar mejor el comportamiento de elección y, como corolario, las predicciones son más precisas.<br>\n",
    "(2) Conceptualmente, el modelo MNL lineal aditivo es demasiado simplista para captar las complejidades del comportamiento de elección humano real.<br>\n",
    "\n",
    "`C` \n",
    "- Utilizar el modelo MNL para probar las interacciones/no linealidades esperadas\n",
    "- Probar numerosas especificaciones para el L-MNL, en términos de características. \n",
    "- Evalúe la especificación en términos de ajuste, pero también en términos de WTP implícitas. \n",
    "- Realice un ajuste adecuado de los hiperparámetros.\n",
    "- Comparar siempre los resultados con el RUM-MNL. \n",
    "- Tener en cuenta la estocasticidad del modelo L-MNL promediando numerosas ejecuciones. \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
