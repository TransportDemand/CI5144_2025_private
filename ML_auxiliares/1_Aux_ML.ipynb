{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demanda de transporte\n",
    "\n",
    "## `Auxiliar: Redes neuronales artificiales`\n",
    "\n",
    "**Junio 2024**<br>\n",
    "**Gabriel Nova & Sander van Cranenburgh** <br>\n",
    "**G.N.Nova@tudelft.nl** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Instrucciones`\n",
    "\n",
    "**Las sesiones de laboratorio son:**<br>\n",
    "* Entornos de aprendizaje donde trabajas con Jupyter y puedes resolver dudas.<br>\n",
    "* No son calificadas y no tienen que ser entregadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Aplicación: Modelo de elección de modos de transporte`\n",
    "\n",
    "En este auxiliar, se busca analizar el comportamiento de elección de modos de transporte. Comprender las preferencias de las personas sobre los atributos de transporte es crucial para los planificadores urbanos cuando desarrollan políticas para mejorar la movilidad urbana sostenible. Durante esta sesión de laboratorio, aplicarás modelos de elección discreta para descubrir las preferencias de las personas sobre atributos como el tiempo de viaje, el costo del viaje, el tiempo de acceso y el nivel de servicio. Además, explorarás si las preferencias interactúan con covariables como género, propósito de viaje y e ingresos. Mientras lo haces, probarás varias especificaciones de utilidad e interpretarás los resultados del modelado de los modelos de elección discreta.\n",
    "\n",
    "Para este estudio, utilizamos datos de un experimento de Elección Declarada (SC) proporcionado por [Apollo](https://www.apollochoicemodelling.com/examples.html)\n",
    "\n",
    "**`Objetivos de aprendizaje del auxiliar`**\n",
    "\n",
    "Después de completar los siguientes ejercicios, podrás: <br>\n",
    "* Preparar datos de (elección) para entrenar Redes Neuronales Artificiales\n",
    "* Entrenar Perceptrón Multicapa (MLP) - un tipo particular de red neuronal - para una tarea de clasificación<br>\n",
    "* Ajustar los hiperparámetros y arquitecturas de la red para mejorar el rendimiento del modelo<br>\n",
    "* Evaluar el rendimiento de modelos cpnvencionales, basados en varias medidas de rendimiento, incluyendo matrices de confusión, precisión, recuperación, F1 y coeficiente de Matthews<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Este laboratorio consta de 6 partes`**\n",
    "1. Preparación de datos (elección) para entrenar Redes Neuronales Artificiales\n",
    "2. Entrenamiento de una red neuronal Perceptrón Multicapa (MLP)\n",
    "3. Uso de detención temprana para evitar el sobreajuste\n",
    "4. Uso de validación cruzada k-fold para evaluar el rendimiento de generalización\n",
    "5. Ajuste de hiperparámetros\n",
    "6. Evaluación del rendimiento de los modelos entrenados\n",
    "\n",
    "y comprende **`7`** ejercicios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Importar packages`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar, importaremos todas las librerías de Python que utilizaremos en el auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar paquetes y módulos Python necesarios\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Importar funciones y clases seleccionadas de paquetes Python\n",
    "from os import getcwd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, log_loss, matthews_corrcoef, make_scorer, classification_report\n",
    "\n",
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, log\n",
    "\n",
    "# Setting\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `0. Preparación de datos (de elección) para entrenar Redes Neuronales Artificiales`\n",
    "Para preparar el conjunto de datos, realizaremos lo siguiente:<br>\n",
    "    1.1 **Cargar** el conjunto de datos<br>\n",
    "    1.2 **Inspeccionar** y **Limpiar** el conjunto de datos<br>\n",
    "    1.3 **Descubrir y visualizar** los datos <br>\n",
    "\n",
    "`i. Configurar el espacio de trabajo y cargar la base de datos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el ruta a la base de datos\n",
    "data_path =  Path(f'data/apollo_modeChoiceData.csv')\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de elección de modo en un pandas DataFrame\n",
    "df = pd.read_csv(data_path,sep = ',')\n",
    "df = df[df['SP']==1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspeccionar y limpiar los datos**<br>\n",
    "Antes de empezar a analizar tus datos, asegúrate de que entiendes qué atributos y características tienen hay en la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción de variables**<br>\n",
    "\n",
    "Por lo tanto, se recomienda revisar la descripción de la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable       | Descripción                                           | Valores                                                |\n",
    "|----------------|-------------------------------------------------------|-------------------------------------------------------|\n",
    "| ID             | Identificador único del individuo                    | 1 a 500                                               |\n",
    "| RP             | Identificador de datos de RP                         | 1 para RP, 0 para SP                                   |\n",
    "| SP             | Identificador de datos de SP                         | 1 para SP, 0 para RP                                   |\n",
    "| RP_journey     | Índice para observaciones de RP                      | 1 a 2, NA para SP                                      |\n",
    "| SP_task        | Índice para observaciones de SP                      | 1 a 14, NA para RP                                     |\n",
    "| av_car         | Disponibilidad para la alternativa 1 (coche)         | 1 para disponible, 0 para no disponible               |\n",
    "| av_bus         | Disponibilidad para la alternativa 2 (autobús)      | 1 para disponible, 0 para no disponible               |\n",
    "| av_air         | Disponibilidad para la alternativa 3 (avión)        | 1 para disponible, 0 para no disponible               |\n",
    "| av_rail        | Disponibilidad para la alternativa 4 (tren)         | 1 para disponible, 0 para no disponible               |\n",
    "| time_car       | Tiempo de viaje (minutos) para la alternativa 1 (coche) | Mín: 250, media: 311.79, máx: 390 (0 si no está disponible) |\n",
    "| cost_car       | Costo de viaje (£) para la alternativa 1 (coche)    | Mín: 30, media: 39.99, máx: 50 (0 si no está disponible) |\n",
    "| time_bus       | Tiempo de viaje (minutos) para la alternativa 2 (autobús) | Mín: 300, media: 370.29, máx: 420 (0 si no está disponible) |\n",
    "| cost_bus       | Costo de viaje (£) para la alternativa 2 (autobús)  | Mín: 15, media: 25.02, máx: 35 (0 si no está disponible) |\n",
    "| access_bus     | Tiempo de acceso (minutos) para la alternativa 2 (autobús) | Mín: 5, media: 15.02, máx: 25 (0 si no está disponible) |\n",
    "| time_air       | Tiempo de viaje (minutos) para la alternativa 3 (avión) | Mín: 50, media: 70.07, máx: 90 (0 si no está disponible) |\n",
    "| cost_air       | Costo de viaje (£) para la alternativa 3 (avión)    | Mín: 50, media: 79.94, máx: 110 (0 si no está disponible) |\n",
    "| access_air     | Tiempo de acceso (minutos) para la alternativa 3 (avión) | Mín: 35, media: 45.02, máx: 55 (0 si no está disponible) |\n",
    "| service_air    | Calidad del servicio para la alternativa 3 (avión)   | 1 para básico, 2 para wifi, 3 para comida (0 si no se usa, datos de RP) |\n",
    "| time_rail      | Tiempo de viaje (minutos) para la alternativa 4 (tren) | Mín: 120, media: 142.93, máx: 170 (0 si no está disponible) |\n",
    "| cost_rail      | Costo de viaje (£) para la alternativa 4 (tren)     | Mín: 35, media: 55.03, máx: 75 (0 si no está disponible) |\n",
    "| access_rail    | Tiempo de acceso (minutos) para la alternativa 4 (tren) | Mín: 5, media: 14.96, máx: 25 (0 si no está disponible) |\n",
    "| service_rail   | Calidad del servicio para la alternativa 4 (tren)    | 1 para básico, 2 para wifi, 3 para comida (0 si no se usa, datos de RP) |\n",
    "| female         | Variable ficticia para individuos femeninos          | 1 para femenino, 0 para otro                           |\n",
    "| business       | Variable ficticia para viajes de negocios            | 1 para viajes de negocios, 0 para otro                 |\n",
    "| income         | Variable de ingresos (£ por año)                     | Mín: 15,490, media: 44,748.27, máx: 74,891             |\n",
    "| choice         | Variable de elección                                 | 1 para coche, 2 para autobús, 3 para avión, 4 para tren |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Estadísticas descriptivas`**<br>\n",
    "\n",
    "Podemos usar `describe()` para ver estadísticas descriptivas, como recuento, media, desviación estándar, mínimo, percentiles y máximo sobre los **niveles de atributos** de las alternativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de datos\n",
    "\n",
    "# Lista de id relevantes\n",
    "id         = ['ID', 'SP_task' ] \n",
    "\n",
    "# Atributos de modos de transporte\n",
    "attributes =   ['time_car',  'cost_car', \n",
    "                'time_bus',  'cost_bus',  'access_bus',\n",
    "                'time_air',  'cost_air',  'access_air',  'service_air', \n",
    "                'time_rail', 'cost_rail', 'access_rail', 'service_rail']\n",
    "\n",
    "# Características: Variable socio-demograficas\n",
    "sociovars = ['female', 'business','income']\n",
    "\n",
    "# Disponibilidad de modos de transporte\n",
    "av = ['av_car', 'av_bus', 'av_rail', 'av_air']\n",
    "\n",
    "# Creacion de dataframe con las variables de interés\n",
    "dff = df[id + attributes + sociovars + av +['choice'] ].copy()\n",
    "\n",
    "print(dff.shape)\n",
    "dff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descubriendo y visualizando los datos**<br>\n",
    "Antes de comenzar a analizar sus datos con modelos, es recomendable comenzar con algunos **análisis descriptivos**.<br>\n",
    "Por lo tanto, se recomienda primero observar la distribución y correlaciones de las características clave en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``Ejercicio 1: ¿La base de datos está (des)balanceada?``\n",
    "`A` Crea un histograma que muestre con qué frecuencia se eligen Auto, Bus, Avión y Tren. No olvides agregar etiquetas a las columnas<br>\n",
    "`B` Interpreta el histograma. ¿La base de datos está (des)balanceada?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``Ejercicio 2: Explorar correlaciones entre características``\n",
    "`A` Crea un mapa de calor para identificar qué características se correlacionan particularmente con la variable **Choice**<br>\n",
    "`B` Identifica las características que se correlacionan fuertemente (corr >0.9) (si las hay). ¿Tienen sentido?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `1. Estimar modelo de elección discreta de referencia`<br>\n",
    "Como referencia, utilizamos el modelo de maximización de la utilidad aleatoria lneal en los parámetros. Estimamos este modelo usando `biogeme`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la base de datos dff en una base de datos biogeme\n",
    "biodata = db.Database('Apollo_mode_choice_data', dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear variables Biogeme\n",
    "\n",
    "# Attributes of alternative 1\n",
    "time_car     = Variable('time_car')\n",
    "cost_car     = Variable('cost_car')\n",
    "\n",
    "# Attributes of alternative 2    \n",
    "time_bus     = Variable('time_bus')\n",
    "cost_bus     = Variable('cost_bus')\n",
    "access_bus   = Variable('access_bus')\n",
    "    \n",
    "# Attributes of alternative 3\n",
    "time_air     = Variable('time_air')\n",
    "cost_air     = Variable('cost_air')\n",
    "access_air   = Variable('access_air')\n",
    "service_air  = Variable('service_air')\n",
    "\n",
    "# Attributes of alternative 4\n",
    "time_rail     = Variable('time_rail')\n",
    "cost_rail     = Variable('cost_rail')\n",
    "access_rail   = Variable('access_rail')\n",
    "service_rail  = Variable('service_rail')\n",
    "\n",
    "# Availability variables\n",
    "av_car       = Variable('av_car')\n",
    "av_bus       = Variable('av_bus')\n",
    "av_rail      = Variable('av_rail')\n",
    "av_air       = Variable('av_air')\n",
    "\n",
    "# choice\n",
    "choice      = Variable('choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dar nombre al modelo    \n",
    "model_name = 'Linear-additive RUM-MNL'\n",
    "\n",
    "# Define los parámetros del modelo, usando la función «Beta()», en la cual debes definir:\n",
    "B_time        = Beta('B_time',      0, None, None, 0)\n",
    "B_cost        = Beta('B_cost',      0, None, None, 0)\n",
    "B_access      = Beta('B_access',    0, None, None, 0)\n",
    "B_service     = Beta('B_service',   0, None, None, 0)\n",
    "ASC_car       = Beta('ASC_car',     0, None, None, 1)\n",
    "ASC_bus       = Beta('ASC_bus',     0, None, None, 0)\n",
    "ASC_air       = Beta('ASC_air',     0, None, None, 0)\n",
    "ASC_rail      = Beta('ASC_rail',    0, None, None, 0)\n",
    "\n",
    "# Definir la forma funcional de las utilidades\n",
    "V1 = ASC_car +  B_time * time_car   + B_cost * cost_car\n",
    "V2 = ASC_bus +  B_time * time_bus   + B_cost * cost_bus  + B_access * access_bus\n",
    "V3 = ASC_air +  B_time * time_air   + B_cost * cost_air  + B_access * access_air  + B_service * service_air\n",
    "V4 = ASC_rail + B_time * time_rail + B_cost * cost_rail + B_access * access_rail + B_service * service_rail\n",
    "\n",
    "# Construir un diccionario con las utilidades de cada alternativa\n",
    "V = {1: V1, 2: V2, 3: V3, 4: V4}    \n",
    "\n",
    "# Construir un diccionario con las disponibilidad de cada alternativa\n",
    "AV = {1: av_car, 2: av_bus, 3: av_air, 4: av_rail} \n",
    "\n",
    "# Definicion del modelo. Es decir, es la contribución de cada observación a la función log likelihood.\n",
    "prob = models.logit(V, AV, choice)\n",
    "\n",
    "# Crear el objeto Biogeme\n",
    "biogeme = bio.BIOGEME(biodata, log(prob))\n",
    "\n",
    "# Configurar reporte\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "# Calcular el valor de la funcion loglikelihood con parametros nulos para el reporte\n",
    "biogeme.calculate_null_loglikelihood(AV)\n",
    "\n",
    "# Estimar paramtetros\n",
    "results_rum_mnl = biogeme.estimate()\n",
    "print(results_rum_mnl.short_summary())\n",
    "\n",
    "# Presentar los resultados en una tabla\n",
    "beta_hat = results_rum_mnl.get_estimated_parameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `2. Entrenamiento de una red neuronal de perceptrón multicapa (MLP)`\n",
    "Para entrenar Redes Neuronales Artificiales, seguimos los siguientes pasos:<br>\n",
    "    2.1 **Esclar** las características<br>\n",
    "    2.2 **Separar** los datos en un conjunto de datos de entrenamiento y evaluación<br>\n",
    "    2.3 **Crear el objeto MLP**<br>\n",
    "    2.4 **Entrenar el MLP** en los datos de entrenamiento<br>\n",
    "    2.5 **Evaluar** el rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Escalar las características`<br>\n",
    "\n",
    "Para entrenar eficientemente ANNs, se recomienda encarecidamente **escalar** (también conocido como normalizar) las características. \n",
    "\n",
    "Hay varias formas de escalar sus datos. Un escalador comúnmente utilizado de `sk-learn` se llama 'StandardScaler'. Este escalador normaliza la varianza y desplaza la ubicación de la distribución a cero, consulte https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea la lista de características que necesitan ser escaladas.\n",
    "# Importante, esto excluye las disponibilidades y la elección\n",
    "features2scale = attributes + sociovars \n",
    "\n",
    "# Iniciar objeto escalador y ajustar a los datos\n",
    "scaler = StandardScaler()  \n",
    "dff_scaled_f = scaler.fit_transform(dff.loc[:,features2scale]) \n",
    "dff_scaled_f = pd.DataFrame(dff_scaled_f, columns = features2scale) \n",
    "dff_scaled_f.reset_index(drop=True, inplace=True)  # Reset indices\n",
    "\n",
    "# Crear un nuevo dataframe X_scaled que contenga las características escaladas Y las (no escaladas)\n",
    "dff_scaled = dff.copy()\n",
    "dff_scaled.reset_index(drop=True, inplace=True)\n",
    "dff_scaled[features2scale] = dff_scaled_f\n",
    "dff_scaled_f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Separar los datos en un conjunto de entrenamiento y un conjunto de evaluación`<br>\n",
    "\n",
    "Entrenar modelos de ML siempre implica un conjunto de datos de **entrenamiento** y un conjunto de datos de **evaluación**. \n",
    "\n",
    "El conjunto de entrenamiento se utiliza para actualizar los pesos(coeficientes) del modelo. El conjunto de evaluación se utiliza para evaluar el **generalización de rendimiento** del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la lista de características que queremos utilizar en el modelo\n",
    "\n",
    "features = attributes + sociovars + av\n",
    "\n",
    "# Crear la variable objetivo\n",
    "Y = dff_scaled['choice']\n",
    "\n",
    "# Divide los datos usando la función `train_test_split` de sk-learn.\n",
    "# Tenga en cuenta que utilizamos el 60% para el entrenamiento y el 40% para la evaluación\n",
    "# Tenga en cuenta que fijamos el random_state, con el fin de replicar los resultados más tarde (no cambiar) \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dff_scaled[features], Y, random_state = 12345, test_size = 0.4)\n",
    "\n",
    "# Almacenar los índices de los conjuntos de pruebas para su uso posterior\n",
    "test_indices = X_test.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Creación del objeto MLP`<br>\n",
    "\n",
    "Un Perceptrón Multicapa (MLP) es una red neuronal que sus nodos estan completamente conectados. Creamos el MLP usando la función MLPClassifier de `sk-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el objeto mlp basico\n",
    "# Declaramos el número de capas y nodos por capa\n",
    "# layers = (a,b) significa dos capas con a nodos en la 1ra capa oculta y b nodos en la 2da capa oculta\n",
    "layers = (90,)\n",
    "\n",
    "# Definimos la arquitectura del MLP, el optimizador y los hiperparámetros:\n",
    "# Usamos el optimizador Adam\n",
    "# Usamos una tasa de aprendizaje de 0.001\n",
    "# Usamos regularización L2 de 0\n",
    "# Usamos un batch_size de 250 observaciones\n",
    "# Usamos la función de activación relu\n",
    "# Establecemos el número máximo de épocas en 2000\n",
    "mlp = MLPClassifier(hidden_layer_sizes=layers, solver='adam', learning_rate_init=0.001, alpha=0, batch_size=250, activation='relu', max_iter=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Entrenando el MLP`<br>\n",
    "Para entrenar el MLP, usamos la función '.fit'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el MLP usando los datos de entrenamiento\n",
    "mlp.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es buena práctica observar la curva de aprendizaje para ver cuánto ha mejorado el modelo desde el punto inicial y cómo ha evolucionado a lo largo de las épocas.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.plot(mlp.loss_curve_)\n",
    "ax.set_xlabel('Época')\n",
    "ax.set_ylabel('Pérdida de entropía cruzada')\n",
    "ax.grid(True, linewidth=0.5)\n",
    "ax.set_ylim(0.4, 1.2)\n",
    "ax.set_xlim(0, mlp.n_iter_)\n",
    "ax.set_title(f'Pérdida de entropía cruzada considerando los datos de entrenamiento. \\nMejor CE = {mlp.loss_:4.3f}')\n",
    "\n",
    "# El gráfico ilustra que el entrenamiento se detiene cuando la pérdida de entrenamiento ya no mejora más que una tolerancia dada (por ejemplo, 1e-6), o alcanza max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`v. Evaluar el rendimiento del modelo` <br>\n",
    "\n",
    "Los investigadores de ML suelen evaluar el rendimiento de un modelo de clasificación utilizando la entropía cruzada.  Una entropía cruzada más baja indica un mejor modelo. \n",
    "\n",
    "En cambio, los modeladores de elección suelen mirar la log-verosimilitud (LL) y el rho-cuadrado. Un LL y rho-cuadrado altos indican un mejor modelo. <br>\n",
    "\n",
    "Como no hay una función estándar que genere las métricas de evaluación de ambas disciplinas, a continuación creamos nuestra **propia función de evaluación**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función de evaluación que devuelve métricas principales de evaluación: LL, LL0, cross_entropy, rho_sq\n",
    "# Para calcular estas métricas de rendimiento, la función toma como entradas:\n",
    "#   - Las probabilidades predichas (prob)\n",
    "#   - Las elecciones (Y)\n",
    "#   - Las disponibilidades (AV)\n",
    "def eval_performance(prob,Y,AV):\n",
    "    \n",
    "    # Calcular la probabilidad de los datos dado el modelo\n",
    "    LL = np.sum(np.log(np.sum(prob*Y,axis=1)))\n",
    "\n",
    "    #  Calcular la Null-loglikelihood\n",
    "    LL0 = np.sum(np.log(np.divide(1,np.sum(AV,axis=1))))\n",
    "\n",
    "    # Calcular la entropía cruzada\n",
    "    cross_entropy =  -LL/len(AV)\n",
    "    \n",
    "    # Calcular el rho_sq\n",
    "    rho_sq = 1 -(LL/LL0)\n",
    "    return LL, LL0, cross_entropy, rho_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usemos nuestra función para evaluar y comparar el rendimiento de nuestro MLP en los conjuntos de datos de entrenamiento y prueba\n",
    "\n",
    "eval_train = eval_performance(mlp.predict_proba(X_train),np.transpose([Y_train ==1,Y_train ==2,Y_train ==3, Y_train ==4]), X_train[['av_car','av_bus','av_rail','av_air']])\n",
    "eval_test  = eval_performance(mlp.predict_proba(X_test), np.transpose([Y_test  ==1,Y_test  ==2,Y_test  ==3, Y_test  ==4]), X_test[['av_car','av_bus','av_rail','av_air']])\n",
    "\n",
    "# Imprimir los resultados\n",
    "print('Model performance of the plain vanilla MLP:')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "results = pd.DataFrame({'data set':     ['Train','Test'],\n",
    "                        'LL':           [eval_train[0], eval_test[0]],\n",
    "                        'LL0':          [eval_train[1], eval_test[1]],\n",
    "                        'cross_entropy':[eval_train[2], eval_test[2]],\n",
    "                        'rho_sq':       [eval_train[3], eval_test[3]]})\n",
    "print(results.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacerse una idea del rendimiento de este MLP base, a continuación se muestran las mismas métricas de rendimiento para un modelo RUM-MNL (considerando todos los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'LL\\t\\t {results_rum_mnl.getGeneralStatistics()[\"Final log likelihood\"][0]:0.2f} \\\n",
    "      \\nLL0\\t\\t {results_rum_mnl.getGeneralStatistics()[\"Null log likelihood\"][0]:0.2f} \\\n",
    "      \\ncross_entropy\\t {-results_rum_mnl.getGeneralStatistics()[\"Final log likelihood\"][0]/len(dff):0.2f} \\\n",
    "      \\nrho_sq\\t\\t {results_rum_mnl.getGeneralStatistics()[\"Rho-square for the null model\"][0]:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Como puede verse, el ajuste del modelo MLP es considerablemente superior al del modelo RUM-MNL lineal aditivo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Ejercicio 3: ¿El uso de más nodos mejora el rendimiento del modelo?``\n",
    "\n",
    "`A` Calcula el número de pesos utilizados por el MLP actual con 10 nodos en 1 capa oculta. <br>\n",
    "`B` Vuelve a entrenar tu modelo varias veces con {10,30,60,90} nodos. Reporta el rendimiento de la entropía cruzada en los conjuntos de datos de entrenamiento y prueba.<br>\n",
    "`C` ¿Aumentar el número de nodos conduce a una entropía cruzada más baja en el conjunto de datos de entrenamiento y/o prueba? ¿Qué está sucediendo?<br>\n",
    "`D` Supongamos que tendrías muchas más observaciones de elección de esta encuesta. ¿Eso te permitiría desarrollar un modelo mejor con un rendimiento de entropía cruzada de, digamos, <0.10 (en el conjunto de prueba)? Explica tu respuesta. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3. Utilizando Early Stopping para evitar el sobreajuste`\n",
    "\n",
    "Early stopping se refiere a una técnica que detiene el entrenamiento de la red cuando el rendimiento en el conjunto de datos de prueba ya no mejora. \n",
    "De esta manera, el early stopping evita que el modelo se sobreajuste a los datos. Básicamente detiene el entrenamiento antes de que el modelo pueda sobreajustarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota: este es el mismo MLP 'base', pero ahora establecemos early_stopping = True\n",
    "# Se agrega una fracción de validación. Esta fracción es la proporción de datos de entrenamiento que se reserva como conjunto de validación para la parada anticipada. Este conjunto de datos se utiliza para determinar cuándo detenerse.\n",
    "# El entrenamiento se detiene cuando el rendimiento en el conjunto de datos de validación no mejora durante n_iter_no_change seguidos\n",
    "# Usamos el MLP con 10 nodos y una capa oculta nuevamente.\n",
    "layers = (90)\n",
    "n_iter_no_change = 10\n",
    "mlp_early_st = MLPClassifier(hidden_layer_sizes = layers, solver='adam', learning_rate_init = 0.001, alpha=0, batch_size=250, activation = 'relu', max_iter = 2000, early_stopping=True, n_iter_no_change = n_iter_no_change,validation_fraction = 0.25) \n",
    "\n",
    "\n",
    "# Entrena el MLP usando los datos de entrenamiento\n",
    "# Tenga en cuenta que utilizamos df.values aquí. Esto es debido a un pequeño error en sk-learn. Sin .values sk-learn todavía funciona, pero muestra algunas advertencias\n",
    "mlp_early_st.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es una buena práctica mirar la curva de aprendizaje, para ver cuánto ha mejorado el modelo desde el punto inicial,\n",
    "# y cómo ha evolucionado a lo largo de las épocas.\n",
    "# El gráfico de la curva de aprendizaje también ilustra bien lo que hace el early_stopping.\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "plt.plot(mlp.loss_curve_,label=f'MLP with {mlp.hidden_layer_sizes} hidden nodes, WITHOUT early stopping')\n",
    "plt.plot(mlp_early_st.loss_curve_,label=f'MLP with {mlp_early_st.hidden_layer_sizes} hidden nodes, WITH early stopping')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Cross entropy loss')\n",
    "ax.grid(True,linewidth = 0.5)\n",
    "ax.set_ylim(0.4,1.2)\n",
    "ax.set_xlim(0,mlp.n_iter_)\n",
    "ax.set_title('Effect of early stopping')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usemos nuestra función de evaluación de nuevo para evaluar el rendimiento del MLP con parada temprana en el conjunto de datos de entrenamiento y prueba\n",
    "eval_train_early_st = eval_performance(mlp_early_st.predict_proba(X_train.values),np.transpose([Y_train ==1,Y_train ==2,Y_train ==3, Y_train ==4]), X_train[['av_car','av_bus','av_rail','av_air']])\n",
    "eval_test_early_st  = eval_performance(mlp_early_st.predict_proba(X_test.values), np.transpose([Y_test  ==1,Y_test  ==2,Y_test  ==3, Y_test  ==4]), X_test[['av_car','av_bus','av_rail','av_air']])\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "results_early_st = pd.DataFrame({'data set':     ['Train','Test'],\n",
    "                        'LL':           [eval_train_early_st[0], eval_test_early_st[0]],\n",
    "                        'LL0':          [eval_train_early_st[1], eval_test_early_st[1]],\n",
    "                        'cross_entropy':[eval_train_early_st[2], eval_test_early_st[2]],\n",
    "                        'rho_sq':       [eval_train_early_st[3], eval_test_early_st[3]]})\n",
    "print(results_early_st.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Ejercicio 4: ¿Podemos sobreajustar con early stopping?``\n",
    "`A` ¿La parada anticipada redujo el sobreajuste? ¿Cómo puedes ver esto en los resultados impresos?<br>\n",
    "`B` Intenta si la parada anticipada también ayuda a evitar el sobreajuste cuando se usan más nodos, por ejemplo, 100, o (50,50) nodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4. Utilizando la validación cruzada k-fold para evaluar la generalización del rendimiento`\n",
    "\n",
    "La validación cruzada k-fold se utiliza comúnmente para **evaluar más precisamente la generalización del rendimiento** de una red dada. Mejora un enfoque simple de dividir sistemáticamente el conjunto de datos en k partes. La validación cruzada k-fold es especialmente crucial cuando se ajustan hiperparámetros (como veremos más adelante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear objeto MLP (MLP 'base' sin parada anticipada)\n",
    "layers = 10\n",
    "mlp_cv = MLPClassifier(hidden_layer_sizes = layers, solver='adam', learning_rate_init = 0.001, alpha=0, batch_size=250, activation = 'relu', max_iter = 2000) \n",
    "\n",
    "# Crear función de evaluación\n",
    "# Es necesario crear una función de evaluación cuando se trabaja con cross_validate de sk-learn\n",
    "# Establecemos `greater_is_better` en `False` ya que estamos minimizando la pérdida de entropía cruzada\n",
    "\n",
    "logloss = make_scorer(log_loss, greater_is_better = False, needs_proba = True)\n",
    "\n",
    "# Aplicar cross_validate, utilizando por ejemplo 5 folder\n",
    "# Dado que usamos validación cruzada, el entrenamiento lleva n_folds veces más tiempo que usar una división de entrenamiento-prueba\n",
    "n_folds = 5\n",
    "cv_results = cross_validate(mlp_cv,dff_scaled[features],Y, cv = n_folds, scoring=logloss,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar el rendimiento de entrenamiento y prueba en un gráfico de barras, para cada fold\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x_axis = np.arange(n_folds)\n",
    "ax.bar(x_axis + -0.125, -cv_results['train_score'], color = 'b', width = 0.25,label = 'Train data set')\n",
    "ax.bar(x_axis +  0.125, -cv_results['test_score'], color = 'g', width = 0.25,label = 'Test data set')\n",
    "ax.set_xlabel('fold #')\n",
    "ax.set_ylabel('cross entropy')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Por tanto, este análisis de validación cruzada respalda la conclusión de que un MLP sencillo (es decir, sin parada temprana) overfit «moderadamente» a los datos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `5. Ajuste de hiperparámetros`\n",
    "\n",
    "Al entrenar MLPs (y la mayoría de otros modelos de ML), hay varios parámetros que podemos **'ajustar'** (optimizar) para mejorar el rendimiento del modelo. El proceso de hacer esto se llama **ajuste de hiperparámetros**. El ajuste de hiperparámetros se puede hacer manualmente, pero eso es engorroso. La función GridSearchCV en `sk-learn` automatiza el proceso de ajuste de hiperparámetros. Cuando se ajustan los hiperparámetros, es obligatorio utilizar un enfoque de validación cruzada k-fold. De lo contrario, existe el riesgo de sobreajustar en el conjunto de prueba *porque* los parámetros se pueden ajustar hasta que el estimador funcione de manera óptima en el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################################\n",
    "\n",
    "# No cambies estas líneas (aseguran que el código se ejecute lo suficientemente rápido en colab y local, reduciendo el nº de iteraciones para colab) ##\n",
    "\n",
    "#######################################################################################################################################################\n",
    "\n",
    "try:\n",
    "    num_iters \n",
    "except NameError:\n",
    "    num_iters = 2000\n",
    "else:\n",
    "    num_iters = 250\n",
    "\n",
    "# Crear el objeto MLP (base MLP)\n",
    "mlp_gs = MLPClassifier(activation = 'relu', solver='adam', batch_size=250, max_iter=num_iters)\n",
    "\n",
    "# Define el espacio de búsqueda de hiperparámetros\n",
    "# 'hidden_layer_sizes' define el número de nodos y capas\n",
    "# 'alpha' gobierna la regularización L2\n",
    "# 'learning_rate_init' gobierna la tasa de aprendizaje.\n",
    "\n",
    "hyperparameter_space = {\n",
    "    'hidden_layer_sizes': [(10),(10,10),(30,30)],\n",
    "    'alpha': [0,0.01,1],\n",
    "    'learning_rate_init': [0.01,0.001,0.0001]}\n",
    "\n",
    "# Crear la funcion de evalaución\n",
    "logloss = make_scorer(log_loss, greater_is_better = False, needs_proba = True)\n",
    "\n",
    "# Crear el objeto grid_search, con el uso del clasificador MLP\n",
    "\n",
    "folds = 5 # Número de divisiones de validación cruzada\n",
    "mlp_gridsearch = GridSearchCV(mlp_gs, hyperparameter_space, n_jobs=-1, cv=folds,scoring = logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el entrenamiento/búsqueda en cuadrícula\n",
    "# ¡Ten en cuenta que esto es costoso computacionalmente! \n",
    "# Puede tardar hasta 5 minutos, ya que hay que entrenar 3 x 3 x 3 = 27 modelos, cada uno con 5 pliegues (=135)\n",
    "mlp_gridsearch.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarde los resultados del ajuste de hiperparámetros para que sólo tengamos que hacerlo una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'my_tuned_model.sav'\n",
    "pickle.dump(mlp_gridsearch, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your model (if you have a saved model)\n",
    "# mlp_gridsearch = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar los resultados del ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recoger los resultados en un nuevo marco de datos pandas\n",
    "df_gridsearch = pd.DataFrame.from_dict(mlp_gridsearch.cv_results_)\n",
    "    \n",
    "#Añada una nueva columna con una etiqueta para las combinaciones de hiperparámetros %% AÚN ESTO NO ES LA MEJOR FORMA DE HACERLO EN PYTHON   \n",
    "df_gridsearch['gs_combinations'] = 'L2 = '+ df_gridsearch['param_alpha'].astype('str') + '; Learning_rate = '+ df_gridsearch['param_learning_rate_init'].astype('str') + '; Layers = ' + df_gridsearch['param_hidden_layer_sizes'].astype('str')\n",
    "df_gridsearch = df_gridsearch.sort_values('rank_test_score')\n",
    "\n",
    "# Visualizar la desviación en el rendimiento a través de la configuración de hiperparámetros.\n",
    "plt.figure(figsize = (16,6))\n",
    "ax = sns.barplot(x = df_gridsearch.gs_combinations,y=-df_gridsearch.mean_test_score,palette=\"Blues_d\",)\n",
    "ax.set_ylim(0.6,1.2)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "print('Best hyperparameters found:\\t', mlp_gridsearch.best_params_)\n",
    "print('Best model performance:\\t\\t', -mlp_gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Ejercicio 5: Ajuste de hiperparámetros``\n",
    "`A` Compara el rendimiento del modelo ajustado de hiperparámetros con el MLP 'base'. ¿Se ha mejorado la generalización del rendimiento ? ¿Cuánto?<br>\n",
    "`B` ¿Qué hiperparámetro resulta ser particularmente impactante en el rendimiento del modelo?<br>\n",
    "`C` ¿Puedes pensar en razones por las que esto podría ser así?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Re)Entrenando el modelo con hiperparámetros optimizados**<br> \n",
    "\n",
    "Después de completar el ajuste de hiperparámetros, conoces los hiperparámetros óptimos. <br>\n",
    "Por lo tanto, después del ajuste de hiperparámetros, siempre volvemos a entrenar el modelo utilizando los hiperparámetros optimizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo objeto mlp usando los hiperparámetros optimizados, sólo usando la división tren/prueba.\n",
    "\n",
    "layers = mlp_gridsearch.best_params_['hidden_layer_sizes']\n",
    "lr = mlp_gridsearch.best_params_['learning_rate_init']\n",
    "alpha = mlp_gridsearch.best_params_['alpha']\n",
    "mlp_gs = MLPClassifier(hidden_layer_sizes = layers, solver='adam', learning_rate_init = lr, alpha=alpha, batch_size=250, activation = 'tanh', max_iter = 2000) \n",
    "\n",
    "# Train the model\n",
    "mlp_gs.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También vamos a evaluar el rendimiento en el modelo hypertuned utilizando nuestra función de evaluación\n",
    "# Nótese que aquí usamos los datos completos\n",
    "eval_gridsearch = eval_performance(mlp_gs.predict_proba(dff_scaled[features]),np.transpose([Y ==1,Y ==2,Y ==3, Y==4]), dff_scaled[['av_car','av_bus','av_rail','av_air']])\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "results_clf = pd.DataFrame({'data set': ['All data'],\n",
    "                        'LL':           [eval_gridsearch[0]],\n",
    "                        'LL0':          [eval_gridsearch[1]],\n",
    "                        'cross_entropy':[eval_gridsearch[2]],\n",
    "                        'rho_sq':       [eval_gridsearch[3]]})\n",
    "print(results_clf.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Evaluación y comparación del rendimiento de los modelos entrenados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el rendimiento, hay una amplia gama de métricas disponibles, más allá del rendimiento de generalización.<br>\n",
    "Aquí, observamos:<br>\n",
    "i. Matriz de confusión<br>\n",
    "ii. Precisión, Sensibilidad y Puntuación F1<br>\n",
    "iii. Coeficiente de correlación de Matthew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i) Matriz de confusión**<br>\n",
    "Las matrices de confusión muestran recuentos de resultados predichos y reales. Los recuentos en la diagonal son resultados clasificados correctamente (las predicciones del modelo y la verdad del suelo son las mismas). Los recuentos en los elementos fuera de la diagonal son los resultados clasificados incorrectamente. Por lo tanto, el mejor clasificador tendrá una matriz de confusión con solo elementos diagonales y el resto de los elementos establecidos en cero.<br>\n",
    "Comparamos el **RUM-MNL** contra el **MLP con ajuste de hiperparámetros**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero tenemos que simular las probabilidades de elección de cada alternativa para cada observación en el conjunto de datos de prueba utilizando biogeme\n",
    "# Utilizándolas, podemos obtener las predicciones 0/1 (basadas en la probabilidad más alta)\n",
    "biodata_sim = db.Database('biodata_sim_test', dff.iloc[test_indices,:])\n",
    "prob_car  = models.logit(V, AV, 1)\n",
    "prob_bus  = models.logit(V, AV, 2)\n",
    "prob_air  = models.logit(V, AV, 3)\n",
    "prob_rail = models.logit(V, AV, 4)\n",
    "\n",
    "# Crear un diccionario con las probabilidad de elección de cada alternativa\n",
    "simulate = {\n",
    "    'Prob. car': prob_car,\n",
    "    'Prob. bus': prob_bus,\n",
    "    'Prob. air': prob_air,\n",
    "    'Prob. rail': prob_rail}\n",
    "\n",
    "# Simular las probabilidad de elección\n",
    "biogeme_sim = bio.BIOGEME(biodata_sim, simulate)\n",
    "simulated_values = biogeme_sim.simulate(results_rum_mnl.getBetaValues())\n",
    "\n",
    "# Obtener 0/1 prediciones basado en la mayor probabilidad\n",
    "Y_pred_mnl = np.argmax(simulated_values.values,axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir las elecciones para el conjunto de datos de prueba, utilizando el MLP entrenado con parada temprana y MLP con hiperparámetros sintonizados.\n",
    "Y_pred_gs = mlp_gs.predict(X_test)                     \n",
    "\n",
    "# Mostrar las matrices de confusión, para comparar la red ajustada a hiperparámetros con la red de parada temprana.\n",
    "fig, ax = plt.subplots(2,2,figsize = (16,12))\n",
    "fig.set_tight_layout(True)\n",
    "ylabels = ['Car', 'Bus', 'Air', 'Rail']\n",
    "cm1 = ConfusionMatrixDisplay.from_predictions(y_true=Y_test,y_pred=Y_pred_mnl, display_labels = ylabels, normalize= None, ax=ax[(0,0)])\n",
    "cm2 = ConfusionMatrixDisplay.from_predictions(y_true=Y_test,y_pred=Y_pred_mnl, display_labels = ylabels, normalize='true',ax=ax[(1,0)])\n",
    "cm3 = ConfusionMatrixDisplay.from_predictions(y_true=Y_test,y_pred=Y_pred_gs,  display_labels = ylabels, normalize= None, ax=ax[(0,1)])\n",
    "cm4 = ConfusionMatrixDisplay.from_predictions(y_true=Y_test,y_pred=Y_pred_gs,  display_labels = ylabels, normalize='true',ax=ax[(1,1)])\n",
    "\n",
    "# Add titles\n",
    "cm1.ax_.set_title(f'RUM-MNL model')\n",
    "cm2.ax_.set_title(f'RUM-MNL model \\n Normalised')\n",
    "cm3.ax_.set_title(f'MLP with {mlp_gs.hidden_layer_sizes} nodes / hyperparameters tuned ')\n",
    "cm4.ax_.set_title(f'MLP with {mlp_gs.hidden_layer_sizes} nodes / hyperparameters tuned \\n Normalised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Ejercicio 6: Precisión del modelo``\n",
    "La precisión se define como los verdaderos positivos sobre el número total de casos.<br>\n",
    "`A` Calcula manualmente la precisión de predicción del modelo RUM-MNL y el modelo con ajuste de hiperparámetros<br>\n",
    "`B` ¿Para qué clase (Carro, Autobús, Avión, Tren) mejora más el ajuste de hiperparámetros la precisión de la predicción?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Añada aquí sus respuestas}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii) Precisión, recuperación y F1**<br>\n",
    "Si se observan las matrices de confusión, las mejoras en la precisión de las predicciones debidas al ajuste de los hiperparámetros pueden no parecer muy impresionantes. Sin embargo, hay que tener en cuenta que las predicciones 0/1 son sensibles a los desequilibrios de clase, que están presentes en estos datos. Además, la precisión puede ser una métrica engañosa para conjuntos de datos desequilibrados. Un modelo ingenuo que simplemente predijera siempre «Ferrocarril» ya lo haría bastante bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el rendimiento del modelo con más profundidad, debemos analizar las predicciones a nivel de las clases.<br>\n",
    "\n",
    "A continuación, calculamos Precisión, Sensibilidad y Puntuación F1.<br>\n",
    "* **Precisión** Te dice qué fracción de las predicciones para una clase dada son realmente de esa clase.<br>\n",
    "* **Sensibilidad** Indica qué fracción de todas las observaciones pertenecientes a una clase dada son correctamente predichas como tal por el modelo. La Sensibilidad también se conoce como Tasa de Verdaderos Positivos (TVP), Sensibilidad, Probabilidad de Detección.<br>\n",
    "* **Puntuación F1** combina precisión y sensibilidad en una sola medida. Matemáticamente es la media armónica de precisión y sensibilidad. Se puede calcular de la siguiente manera: <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para calcular la precisión, el recal y la puntuación f1 utilizamos convenientemente la funcionalidad 'classification_report' de sk-learn\n",
    "print('Classification report for RUM-MNL model\\n',classification_report(Y_test,Y_pred_mnl, target_names= ylabels))\n",
    "print('\\nClassification report for plain vanilla MLP with hyperparameters tuned\\n',classification_report(Y_test,Y_pred_gs, target_names= ylabels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Demanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
