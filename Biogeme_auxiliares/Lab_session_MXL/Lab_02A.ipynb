{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demanda de transporte\n",
    "\n",
    "## `Auxiliar: Redes neuronales artificiales`\n",
    "\n",
    "**Junio 2024**<br>\n",
    "**Gabriel Nova & Sander van Cranenburgh** <br>\n",
    "**G.N.Nova@tudelft.nl** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Application: Estimating the Value of Travel Time`\n",
    "\n",
    "In this lab session, we will investigate the \"Value of Travel Time\" (VTT) distribution. The VTT of a traveller reflects the amount of money the traveller is **willing to pay** to reduce their travel time. The VTT is used to determine the benefits of new infrastructure projects. As travel time savings are the dominant and most salient benefits of new infrastructure, accurate inference of the distribution of the VTT is crucial for a rigorous underpinning of policy decisions. <br>\n",
    "\n",
    "During this lab, we will apply Mixed Logit choice models. We aim to uncover how tastes for travel time and travel cost are distributed in the population. Most of the analyses in this lab session are carried out in the so-called willingness-to-pay space. Willingness-to-pay space facilitates the inference of the VTT distribution.<br>\n",
    "\n",
    "For this study, we will use Stated Choice (SC) data (`Norway_VTT_2009.csv`) collected in 2009 to compute the Norwegian VTT. In this SC experiment, respondents faced nine choice tasks involving two alternatives and two attributes (travel cost and travel time). The data set consists of 5,832 participants, resulting in a total of 52,488 choice observations. The figure below shows one of the choice tasks (note that for the purposes of illustration we converted the currency unit (Kronor) into euros).\n",
    "\n",
    "![SC](data/sc_experiment.png)\n",
    "\n",
    "**`Learning objectives lab session 02A`**\n",
    "\n",
    "After completing the following exercises, you will be able to:\n",
    "* Estimate Mixed Logit models that capture taste heterogeneity and panel effects\n",
    "* Interpret the modelling outcomes of Mixed Logit models\n",
    "* Specify utility models in Willingness-to-pay space\n",
    "\n",
    "\n",
    "\n",
    "**`This lab consists of 4 parts and has 2 exercises`**\n",
    "\n",
    "**Part 1**: Load and explore the data set\n",
    "\n",
    "**Part 2**: Linear-additive RUM-MNL model\n",
    "\n",
    "**Part 3**: Mixed Logit model for capturing taste heterogeneity \n",
    "- Exercise 1: \"Mixed Logit model with a normally distributed beta_tt\"\n",
    "\n",
    "**Part 4**: Willingness-to-Pay space \n",
    "- Exercise 2: \"Mixed Logit model with log-normally distributed VTT\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Import packages`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will import all the libraries that we will use in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biogeme\n",
    "import biogeme.biogeme_logging as blog\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, bioDraws, log, MonteCarlo, exp, bioMultSum, exp\n",
    "\n",
    "# General packages\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm, lognorm\n",
    "\n",
    "# Pandas setting to show all columns when displaying a pandas dataframe\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We invoke a so-called `logger` which enables us to see the progress during estimation.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the logger, if it has not been initialized yet\n",
    "try:\n",
    "    logger\n",
    "except NameError:    \n",
    "    logger = blog.get_screen_logger(level=blog.INFO)\n",
    "    print('Logger has been initialised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `1. Load and explore the data set` <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data set\n",
    "data_path = Path('data/Norway_VTT_2009.csv')\n",
    "df = pd.read_table(data_path, sep=',')\n",
    "\n",
    "# Show descriptive statistics\n",
    "round(df.describe(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set contains the following variables:<br>\n",
    "\n",
    "| Variable       | Description                                                  | Type    |\n",
    "|---------------|-------------------------------------------------------------|---------|\n",
    "| `RespID`        | Unique identifier for each survey response             | Integer |\n",
    "| `CostL`         | Travel cost of left alternative [min]                  | Decimal |\n",
    "| `CostR`         | Travel cost of right alternative [min]                 | Decimal |\n",
    "| `TimeL`         | Travel time of left alternative [eur]                  | Decimal |\n",
    "| `TimeR`         | Travel time of right alternative [eur]                 | Decimal |\n",
    "| `Chosen`        | Indicates the alternative chosen       | Categorical |\n",
    "| `Mode`          | Type of Transport mode               | Categorical    |\n",
    "| `Gender`        | Gender of the respondent                                     | Categorical    |\n",
    "| `AgeClass`      | Classification of the respondent's age                       | Categorical    |\n",
    "| `IncClass`      | Classification of the respondent's income                    | Categorical    |\n",
    "| `Purpose`       | Purpose of the trip                                     | Integer    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we take the following data preprocessing steps:\n",
    "\n",
    "1. We keep only observations for the purpose 'long distance commute' and travel model 'car'.\n",
    "\n",
    "2. We convert the unit of cost from Norwegian Krone to euros to ease interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep only entries purpose == 5 (Long distance trips) & Mode == 1 (Car)\n",
    "df = df.loc[(df['Purpose'] == 5) & (df['Mode'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert the monetary unit to euros\n",
    "NOK2euro_exchange_rate = 9\n",
    "df[['CostL','CostR']] = df[['CostL','CostR']] .div(NOK2euro_exchange_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `2. Linear-additive RUM-MNL model`<br>\n",
    "We first estimate a linear-aditive RUM-MNL model. This model serves as our **benchmark** to compare against. But, before we can do this, we need to create the Biogeme database object and specify the optimiser and logger settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Biogeme database`<br>\n",
    "To estimate a model in Biogeme, we must create the data set as a Biogeme database object and the attributes as Biogeme variable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Biogeme database object\n",
    "biodata = db.Database('Norway2009VTT', df)\n",
    "\n",
    "# Create Biogeme variable objects\n",
    "CostL  = Variable('CostL')\n",
    "CostR  = Variable('CostR')\n",
    "TimeL  = Variable('TimeL')\n",
    "TimeR  = Variable('TimeR')\n",
    "Chosen = Variable('Chosen')\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create a linear-additive RUM-MNL model`<br>\n",
    "Now, we have the biogeme database object and set the environment, we can estimate our first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'Benchmark MNL VTT model'\n",
    "\n",
    "# Define model parameters\n",
    "B_tt = Beta('B_tt', -0.1, None, None, 0)\n",
    "B_tc = Beta('B_tc', -0.1, None, None, 0)\n",
    "\n",
    "# Definition of the utility functions\n",
    "VL = B_tt * TimeL + B_tc * CostL\n",
    "VR = B_tt * TimeR + B_tc * CostR\n",
    "\n",
    "# Associate utility functions with alternatives\n",
    "V = {1: VL, 2: VR}     \n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "av = {1: 1, 2: 1} \n",
    "\n",
    "# Compute probability of the chosen alternative\n",
    "prob = models.logit(V, av, Chosen)\n",
    "\n",
    "# Take the log of the probability\n",
    "logprob = log(prob)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "biogeme = bio.BIOGEME(biodata, logprob)\n",
    "\n",
    "# Compute the null loglikelihood for reporting\n",
    "biogeme.nullLogLike = biogeme.calculate_null_loglikelihood(av)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.save_iterations = False\n",
    "biogeme.modelName = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the MNL model and print the results\n",
    "results = biogeme.estimate()\n",
    "print(results.print_general_statistics())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.get_estimated_parameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Compute the Value of Travel Time`<br><br>\n",
    "The linear-additive RUM-MNL model allows for easy computation of the (mean) VTT. <br>\n",
    "\n",
    "$VTT = {\\frac{dV}{dtt}}/{\\frac{dV}{dtc}}$<br><br>\n",
    "$VTT = \\frac{\\beta_{tt}}{\\beta_{tc}}$\n",
    "\n",
    "To take the ratio, we access the estimated betas in the `beta_hat` dataframe that was created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time and print the mean VTT\n",
    "# We multiply by 60 to convert the value of travel time from minutes to hours\n",
    "VTT_MNL = 60*(beta_hat.loc['B_tt']['Value']/beta_hat.loc['B_tc']['Value'])\n",
    "print(f'Value of travel time MNL model:  €{VTT_MNL:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3. Mixed Logit model for capturing taste heterogeneity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.1 Theory`<br>\n",
    "In the MNL model, we postulate that tastes (e.g., 𝛽_tc) are equal across people in the population. As such, the taste parameter of an MNL model represents the mean taste in the population. The Mixed Logit (ML) model resolves this limitation. It explicitly models taste heterogeneity by means of random variables.\n",
    "\n",
    "Mathematically, the unconditional choice probability is given by:\n",
    "\n",
    "$P_{ni} = \\int_{\\beta_n}    [P_{ni}|\\beta_n] \\cdot f(\\beta_n|\\sigma)d\\beta_n$\n",
    "\n",
    "As can be seen, the ML choice probability does not have a closed-form expression. Therefore, it needs to be approximated using simulation.<br>\n",
    "To do that, we simulate the choice probabilities using a large number of draws `(R)` from the density function $f(β_n|\\sigma)$. <br>\n",
    "That is, we compute the conditional choice probability (which is a simple MNL) for each draw of $\\beta_n^{r}$ with $r=1,..,R$, and then take the average across the draws to compute the unconditional choice probability.\n",
    "\n",
    "<span style=\"text-decoration: overline;\">P</span>$_{ni} = \\frac{1}{R} \\sum_{r=1}^R P_{ni}(β_n^r)$\n",
    "\n",
    "Finally, we use the unconditional choice probabilities to compute the Log-Likelihood of the data given the model:\n",
    "\n",
    "$LL(X,|\\beta,\\sigma)= \\sum_{n=1}^N \\sum_{j=1}^J y_{nj} \\cdot ln($<span style=\"text-decoration: overline;\">P</span>$_{nj})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.2 ML with normally distributed taste parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate an ML, model with normally distributed taste parameters, we must specify the random parameters (for all randomly distributed betas that we wish to estimate). To do this in Biogeme, we use the following code to construct the random parameter for $\\beta_{tt}$:<br>\n",
    "\n",
    "                B_tt_rnd = B_tt + sigma_tt * bioDraws('B_tt_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "Note that apart from the random parameter for B_tt_rnd, the utility function is the same as under our linear-additive RUM-MNL benchmark model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model specification` <br>\n",
    "\n",
    "Now, we will define random and nonrandom parameters, the utility functions, and their availabilities. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "B_tt = Beta('b_tt', -0.1, None, None, 0)\n",
    "B_tc = Beta('b_tc', -0.1, None, None, 0)    \n",
    "sigma_tt = Beta('sigma_tt', 1, None, None, 0)\n",
    "sigma_tc = Beta('sigma_tc', 1, None, None, 0)\n",
    "\n",
    "# Construct the random taste parameter for beta_tt\n",
    "B_tt_rnd = B_tt + sigma_tt * bioDraws('B_tt_rnd', 'NORMAL_HALTON2')\n",
    "B_tc_rnd = B_tc + sigma_tc * bioDraws('B_tc_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "# Definition of the utility functions \n",
    "V_L = B_tt_rnd * TimeL + B_tc_rnd * CostL\n",
    "V_R = B_tt_rnd * TimeR + B_tc_rnd * CostR   \n",
    "\n",
    "# Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "V = {1: V_L, 2: V_R}\n",
    "            \n",
    " # Create a dictionary to describe the availability conditions of each alternative\n",
    "av = {1: 1, 2: 1} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Estimation through simulation` \n",
    "\n",
    "We use the Monte Carlo simulation to estimate the random parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'ML with normal distributed B_tt and B_tc'\n",
    "\n",
    "# The conditional probability of the chosen alternative is a logit\n",
    "condProb = models.logit(V, av ,Chosen)\n",
    "\n",
    "# The unconditional probability is obtained by simulation\n",
    "uncondProb = MonteCarlo(condProb)\n",
    "\n",
    "# The Log-likelihood is the log of the unconditional probability\n",
    "LL = log(uncondProb)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "num_draws = 100\n",
    "biogeme = bio.BIOGEME(biodata , LL,number_of_draws=num_draws)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.save_iterations = False\n",
    "biogeme.modelName = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the model and print the results\n",
    "results = biogeme.estimate()\n",
    "\n",
    "# Print the results in a table\n",
    "# Note that print_general_statistics() gives more information than short_summary(), which we used before\n",
    "print(results.print_general_statistics())\n",
    "\n",
    "# Get the estimated parameters in a pandas table\n",
    "beta_hat = results.get_estimated_parameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.3 Reflection`<br>\n",
    "We can make the following observations from the results of the ML model:\n",
    "1. The model fits the data better than the linear-additive RUM-MNL model. So this model is preferred over the linear-additive RUM-MNL model.\n",
    "2. The estimated standard deviations of the random parameters are significant, indicating that there is substantial taste heterogeneity in the population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However**, the ML model with two normally distributed random parameters does not provide a way to compute the VTT. When we would compute the VTT by taking the ratio of $\\beta_{time}$ over $\\beta_{cost}$ we end up dividing by 0 because the **normal** distribution has mass at zero. In other words, the model predicts some people don't care about cost at all. This implies they would have a infinite VTT, and the mean VTT would be infinite as well. Thus, a normally distributed $\\beta_{tc}$ is generally not a good idea if one want to compute the VTT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 1: Mixed Logit model with a normally distributed beta_tt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Modify the code to estimate the ML model above, such that the model only treat  $\\beta_{tt}$ as a random variable.\n",
    "\n",
    "`B` Compute the **mean** VTT for the model with only $\\beta_{tt}$ as a random variable. The mean of a normal distribution is given by the mean of the random parameter. So, the mean VTT is given by  VTT_ML = $60\\cdot \\frac{\\beta_{tt}}{\\beta_{tc}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4. Willingness-to-Pay space`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.1. Theory`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People are differently sensitive to cost. But, as discussed under 3.3, we cannot specify $\\beta_{tc}$ as a randomly distributed parameter (or, to be more precise, not as one that uses a distribution which has support over the full domain, like a normal distribution). To circumvent this problem, we can cleverly re-parameterise our model. This reparametrisation involves a transformation from **`utility space`** to **`Willingness-to-Pay (WTP) space`**. This transformation allows us to estimate the VTT (distribution) directly, and simplifies the modelling. It works as follows:<br><br>\n",
    "\n",
    "\n",
    "The utility specification in `utility space` is:\n",
    "\n",
    "$V_1 = \\beta_{tc} \\cdot TC_1 + \\beta_{tt} \\cdot TT_1$<br>\n",
    "$V_2 = \\beta_{tc} \\cdot TC_2 + \\beta_{tt} \\cdot TT_2$<br><br>\n",
    "\n",
    "We factorise $\\beta_{tc}$ in both utility functions. This gives us:\n",
    "\n",
    "$V_1 = \\beta_{tc} \\cdot (TC_1 + (\\frac{\\beta_{tt}}{\\beta_{tc}}) \\cdot TT_1)$<br>\n",
    "$V_2 = \\beta_{tc} \\cdot (TC_2 + (\\frac{\\beta_{tt}}{\\beta_{tc}}) \\cdot TT_2)$<br><br>\n",
    "\n",
    "Noting that $VTT = \\frac{\\beta_{tt}}{\\beta_{tc}}$, we obtain:\n",
    "\n",
    "$V_1 = \\beta_{tc} \\cdot (TC_1 + VTT \\cdot TT_1)$<br>\n",
    "$V_2 = \\beta_{tc} \\cdot (TC_2 + VTT \\cdot TT_2)$<br><br>\n",
    "\n",
    "Hence, with this model, we can directly estimate the VTT (and $\\beta_{tc}$). Therefore, this model is in the `Willingness-to-Pay space`.<br> \n",
    "\n",
    "**Starting values for estimating the VTT in the WTP space**<br>\n",
    "Whenever we estimate a discrete choice model, we need to provide starting values for the optimisation algorithm. For conventional linear-additive RUM-MNL models, the starting values are inconsequential because of its concave log-likelihood function. However, for models estimated in WTP space and more complex models in general, the starting values can have impact. When estimating the VTT in the WTP space, it is good practice to provide reasonable starting values (thus a nonzero, positive VTT).\n",
    "\n",
    "In the WTP space, we can use the following heuristic to determine the starting values for the VTT:<br>\n",
    "Let's first see how this works out for a simple MNL model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'Benchmark MNL in WTP space'\n",
    "\n",
    "# Define model parameters\n",
    "vtt  = Beta('vtt', 10/60, None, None, 0) # Note thate we use VTT of 10 euros/hr as the starting value\n",
    "B_tc = Beta('B_tc', -0.1, None, None, 0) # Note that we use a reasonable starting value for B_tc (same as in the MNL model)\n",
    "\n",
    "# Definition of the utility functions\n",
    "VL = B_tc * (CostL + vtt * TimeL)\n",
    "VR = B_tc * (CostR + vtt * TimeR)\n",
    "\n",
    "# Associate utility functions with alternatives\n",
    "V = {1: VL, 2: VR}     \n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "av = {1: 1, 2: 1} \n",
    "\n",
    "# Compute probability of the chosen alternative\n",
    "prob = models.logit(V, av, Chosen)\n",
    "\n",
    "# Take the log of the probability\n",
    "logprob = log(prob)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "biogeme = bio.BIOGEME(biodata, logprob)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.save_iterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "# Compute the null loglikelihood for reporting\n",
    "biogeme.calculate_null_loglikelihood(av)\n",
    "\n",
    "# Estimate the parameters and print the results\n",
    "results = biogeme.estimate()\n",
    "print(results.short_summary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.get_estimated_parameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time\n",
    "VTT_WTP_MNL = 60 * beta_hat.loc['vtt']['Value']\n",
    "print(f'Value of travel time MNL model in WTP space:  €{VTT_WTP_MNL:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.2 Reflection`<br>\n",
    "Comparing these results with the benchmark MNL VTT model, we make two observations:\n",
    "* We obtain `EXACTLY` the same VTT\n",
    "* We obtain `EXACTLY` the same model fit \n",
    "* **We immediately obtain the VTT and the associated standard error!** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.3. ML in Willingness-to-Pay space`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ML with normally distributed taste parameters`<br>\n",
    "Now, let's see how WTP space enables us to directly estimate the VTT distribution in the context of the Mixed Logit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'ML WTP space with normally distributed vtt'\n",
    "\n",
    "# Parameters definition enabling the construction of random parameters\n",
    "vtt = Beta('vtt',    0.1, None, None, 0)\n",
    "B_tc = Beta('b_tc', -0.1, None, None, 0)    \n",
    "sigma_vtt = Beta('sigma_vtt', 1, None, None, 0)\n",
    "\n",
    "# Construction of random parameters   \n",
    "vtt_rnd = vtt + sigma_vtt * bioDraws('vtt_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "# Definition of the utility functions \n",
    "V_L = B_tc * (CostL + vtt_rnd * TimeL)\n",
    "V_R = B_tc * (CostR + vtt_rnd * TimeR)   \n",
    "\n",
    "# Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "V = {1: V_L, 2: V_R}\n",
    "            \n",
    " # Create a dictionary to describe the availability conditions of each alternative\n",
    "av = {1: 1, 2: 1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The conditional probability of the chosen alternative is a logit\n",
    "condProb = models.logit(V, av ,Chosen)\n",
    "\n",
    "# The unconditional probability is obtained by simulation\n",
    "uncondProb = MonteCarlo(condProb)\n",
    "\n",
    "# The Log-likelihood is the log of the unconditional probability\n",
    "LL = log(uncondProb)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "num_draws = 100\n",
    "biogeme = bio.BIOGEME(biodata , LL,number_of_draws=num_draws)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.save_iterations = False\n",
    "biogeme.modelName = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the model and print the results\n",
    "results = biogeme.estimate()\n",
    "\n",
    "# Print the results in a table\n",
    "# Note that print_general_statistics() gives more information than short_summary(), which we used before\n",
    "print(results.print_general_statistics())\n",
    "\n",
    "# Get the estimated parameters in a pandas table\n",
    "beta_hat = results.get_estimated_parameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time\n",
    "VTT_WTP_ML = 60*beta_hat.loc['vtt']['Value']\n",
    "print(f'Value of travel time ML model in WTP space:  €{VTT_WTP_ML:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Visualisation of the estimated VTT distribution`<br>\n",
    "Visualisation of the estimated distribution helps to get a feeling for the shape of the distribution that we aim to recover. To do so, we use the estimated values for the mean (vtt) and standard deviation (sigma_vtt). <br>\n",
    "Note that the visualisation distinguishes between values in the positive and negative domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the estimated normal distribution\n",
    "\n",
    "# Get the mean and standard deviation from the beta_hat table\n",
    "mean_normal = beta_hat.loc['vtt']['Value']\n",
    "std_dev_normal = beta_hat.loc['sigma_vtt']['Value']\n",
    "\n",
    "# Create a vector of 100 points between +/- 4 standard deviations from the mean\n",
    "x= np.linspace(mean_normal - 4*std_dev_normal, mean_normal + 4*std_dev_normal, 100)\n",
    "\n",
    "# Plot the normal distribution in the positive domain. \n",
    "# Note that the x-axis is rescaled by 60 to convert from minutes to hours\n",
    "# The scipy function \"norm.pdf(x,mean, std_dev)\" computes the probability density function of the normal distribution\n",
    "plt.plot(x[x>0]*60, norm.pdf(x[x>0], mean_normal, std_dev_normal))\n",
    "\n",
    "# Plot the normal distribution in the negative domain. \n",
    "plt.plot(x[x<0]*60, norm.pdf(x[x<0], mean_normal, std_dev_normal), color='red',linestyle='dashed')\n",
    "\n",
    "# Add a vertical line to highlight the zero\n",
    "plt.plot([0,0], [0,np.max(norm.pdf(x[x>0], mean_normal, std_dev_normal))], color='black',linestyle='dashed')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('VTT [euro/hour]')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.ylim([0,1])\n",
    "plt.title(f'Distribution of the VTT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.4 Reflection`<br>\n",
    "* Using a Mixed Logit model in the Willingness-to-Pay space, we are able to estimate the distribution of the VTT **directly** . Hence, this model allows jointly for unobserved heterogeneity in cost and time without running into problems caused by dividing by zero.  \n",
    "* But, we see that a substantial part of the VTT distribution lies in the negative domain. This is behaviourally counterintuitive. In general, people prefer to arrive quicker at their destination rather than later. This is due to the assumption that the VTT is normally distributed. Perhaps this assumption needs revisiting...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 2: Mixed Logit with log-normally distributed VTT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **you** will try the assumption that the VTT distribution in the population is **`log-normally distributed`** (as opposed to normally distributed).<br>\n",
    "\n",
    "To do that, you must create a random vtt parameter with a log-normal VTT distribution. Draws from the log-normal distribution can be obtained from draws from the normal distribution as follows: <br>\n",
    "\n",
    "            vtt_rnd = exp(mu + sigma  * bioDraws('vtt_rnd', 'NORMAL_HALTON2'))\n",
    "            \n",
    "\n",
    "Estimate this model and interpret its results.<br>\n",
    "\n",
    "\n",
    "\n",
    "`A` Compare the log-likelihood of the ML model with normal distribution and with log-normal distribution. Which model fits better?<br>\n",
    "\n",
    "`B` What can you conclude from the `vtt` and `sigma` parameters?<br>\n",
    "\n",
    "`C` Compute the mean of the estimated log-normal distribution, i.e. `mean_lognormal` (based on your estimated `mu` and `sigma`). <br>\n",
    "\n",
    "**Hint**, take a look at [https://en.wikipedia.org/wiki/Log-normal_distribution](https://en.wikipedia.org/wiki/Log-normal_distribution) to see how this is done. Look for the formula for the mean in the right-hand side panel on the web page.\n",
    "\n",
    "`D` Plot the shape of the log-normal distribution for the estimated mu and sigma. <br>\n",
    "\n",
    " **Hint**, you can use the  scipy function \"lognorm\". But lognorm is differently parameterised. That is, instead of using a location parameter `mu`, it requires a `scale` parameter. The scale is simply the exponent of the location parameter mu (i.e. scale = exp(mu)). <br>\n",
    "    \n",
    "Alternatively, you compute it directly from the formula yourself using the location `mu` and standard deviation $\\sigma$:<br>\n",
    "    ${\\frac {1}{x\\sigma {\\sqrt {2\\pi }}}}\\ \\exp \\left(-{\\frac {\\left(\\ln x-\\mu \\right)^{2}}{2\\sigma ^{2}}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Demanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
